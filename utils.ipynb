{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Utils Notebook\nEl propósito de este notebook es guardar todas las funciones auxiliares para la implementación del código principal. Se podrá encontrar organizado en diferentes secciones.","metadata":{}},{"cell_type":"markdown","source":"## Set-up","metadata":{}},{"cell_type":"markdown","source":"### Installs","metadata":{}},{"cell_type":"code","source":"!pip install contractions\n!pip install nltk\n!pip install textblob\n!pip install ffmpeg-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime\nimport re\nimport os\nimport json\nimport contractions\nfrom itertools import product\nfrom textblob import TextBlob\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport string\nfrom transformers import BertTokenizer, RobertaTokenizer, XLNetTokenizer, AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, logging\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision.models import VGG16_Weights\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import label_binarize\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\n\nimport ffmpeg\nimport librosa\nimport io\nimport warnings\nimport librosa.display\nfrom scipy.ndimage import zoom\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n\nlogging.set_verbosity_error()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:44:42.913889Z","iopub.execute_input":"2025-04-20T22:44:42.914140Z","iopub.status.idle":"2025-04-20T22:44:44.864142Z","shell.execute_reply.started":"2025-04-20T22:44:42.914120Z","shell.execute_reply":"2025-04-20T22:44:44.862822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Diccionarios y variables globales","metadata":{}},{"cell_type":"code","source":"# Diccionario global con paths base por dataset\nDATASET_PATHS = {\n    'MELD': '/kaggle/input/meld-dataset/MELD-RAW/MELD.Raw/',\n    'MOSEI': '/kaggle/input/cmu-mosei/CMU-MOSEI-20230514T151450Z-001/CMU-MOSEI',\n    'MOSEI_audios': '/kaggle/input/d/maunberg/cmu-mosei/Audio/Audio/WAV_16000/'\n}\n\n# Stopwords de NLTK\nstop_words = set(stopwords.words(\"english\"))\n\n# Tokenizadores para el estudio del sentimiento\ntokenizers = {\n    \"bert\": BertTokenizer.from_pretrained(\"bert-base-uncased\"),\n    \"bertweet\": AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\"),\n    \"roberta\": RobertaTokenizer.from_pretrained(\"roberta-base\"),\n    \"twitter-roberta\": AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\"),\n    \"xlnet\": XLNetTokenizer.from_pretrained(\"xlnet-base-cased\"),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.337074Z","iopub.execute_input":"2025-04-13T19:08:01.337291Z","iopub.status.idle":"2025-04-13T19:08:01.342254Z","shell.execute_reply.started":"2025-04-13T19:08:01.337274Z","shell.execute_reply":"2025-04-13T19:08:01.341450Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Lectura de CSVs","metadata":{}},{"cell_type":"code","source":"def read_csvs(file_paths, dataset_type):\n    \"\"\"\n    Función que lee múltiples archivos CSV desde una ruta base asociada al tipo de dataset.\n\n    Args:\n        file_paths (list): Lista de rutas a los archivos CSV que se deben leer.\n        dataset_type (str): Indetificador del tipo de dataset, utilizada para obtener la ruta base.\n\n    Returns:\n        tuple of pandas.DataFrame: Tupla que contiene un Pandas DataFrame por cada archivo leído.\n\n    Raises:\n        ValueError: Si el tipo de dataset no está definido en DATASET_PATHS.\n    \"\"\"\n    # Path inicial del dataset escogido\n    input_path = DATASET_PATHS.get(dataset_type)\n\n    if not input_path:\n        raise ValueError(f\"Dataset no reconocido: {dataset_type}\")\n\n    # Lectura de todos los CSVs de la lista\n    dfs = [pd.read_csv(os.path.join(input_path, f)) for f in file_paths]\n\n    # Retorno de los dataframes\n    return tuple(dfs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.343959Z","iopub.execute_input":"2025-04-13T19:08:01.344177Z","iopub.status.idle":"2025-04-13T19:08:01.356054Z","shell.execute_reply.started":"2025-04-13T19:08:01.344155Z","shell.execute_reply":"2025-04-13T19:08:01.355464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def shape_dfs(dfs, name_dfs):\n    \"\"\"\n    Función que muestra por consola las dimensiones (filas y columnas) de cada DataFrame proporcionado.\n\n    Args:\n        dfs (list of pandas.DataFrame): Lista de DataFrames cuyas dimensiones se desean mostrar.\n        name_dfs (list of str): Lista de nombres que identifican a cada DataFrame.\n\n    Returns:\n        None: Esta función no retorna ningún valor; imprime resultados por consola.\n    \"\"\"\n    # Por cada dataframe, mostramos sus dimensiones \n    for i in range(len(name_dfs)):\n        print(f\"{name_dfs[i]} tiene {dfs[i].shape[0]} filas y {dfs[i].shape[1]} columnas\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.356766Z","iopub.execute_input":"2025-04-13T19:08:01.356994Z","iopub.status.idle":"2025-04-13T19:08:01.373288Z","shell.execute_reply.started":"2025-04-13T19:08:01.356972Z","shell.execute_reply":"2025-04-13T19:08:01.372588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Limpieza de CSVs","metadata":{}},{"cell_type":"code","source":"def convert_time_to_seconds(time_str):\n    \"\"\"\n    Función que convierte una cadena de tiempo en formato 'HH:MM:SS,MS' a segundos como número decimal.\n\n    Args:\n        time_str (str): Cadena de texto que representa el tiempo de comienzo o fin del clip de audio/video.\n\n    Returns:\n        float: Tiempo expresado en segundos.\n    \"\"\"\n    # Se reemplazan las comas por puntos decimales\n    time_str = time_str.replace(',', '.')\n    \n    # Se transforma el formato HH:MM:SS.MS a segundos\n    h, m, s = time_str.split(':')\n    s, ms = s.split('.')\n    total_seconds = int(h) * 3600 + int(m) * 60 + int(s) + int(ms)/1000\n    return total_seconds\n\ndef convert_time_columns_MELD(df):\n    \"\"\"\n    Función que convierte las columnas 'StartTime' y 'EndTime' de un DataFrame MELD a segundos en formato numérico.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del dataset MELD que contiene las columnas 'StartTime' y 'EndTime'.\n\n    Returns:\n        pandas.DataFrame: DataFrame con las nuevas columnas 'StartTime_sec' y 'EndTime_sec', y sin las columnas originales de tiempo.\n    \"\"\"\n    # Se convierten las columnas de tiempo a valores numéricos\n    df.loc[:, 'StartTime_sec'] = df['StartTime'].apply(convert_time_to_seconds)\n    df.loc[:, 'EndTime_sec'] = df['EndTime'].apply(convert_time_to_seconds)\n    \n    # Se eliminan las columnas innecesarias\n    df = df.drop(columns = ['StartTime', 'EndTime'])\n    return df\n\ndef encode_MOSEI_video_column(df_list):\n    \"\"\"\n    Función que codifica los nombres de los videos en los DataFrames del dataset MOSEI a valores numéricos.\n\n    Args:\n        df_list (list of pandas.DataFrame): Lista con tres DataFrames MOSEI que contienen la columna 'video'.\n\n    Returns:\n        tuple of pandas.DataFrame: Los tres DataFrames MOSEI originales, cada uno con una nueva columna 'video_encoded'.\n\n    Notes:\n        Se utiliza LabelEncoder de scikit-learn para asignar valores únicos a cada nombre de video. El encoder se entrena con la unión de los valores únicos de todos los DataFrames.\n    \"\"\"\n    # Se unen los nombres de los videos de los 3 datasets MOSEI\n    all_videos = pd.concat([df['video'] for df in df_list]).astype(str).unique()\n\n    # Se define y entrena el encoder\n    encoder = LabelEncoder()\n    encoder.fit(all_videos)\n\n    # Cada nombre de video en cada df se codifica a un valor numérico\n    for df in df_list:\n        df.loc[:, 'video_encoded'] = encoder.transform(df['video'].astype(str))\n\n    return df_list[0], df_list[1], df_list[2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_dfs(df, dataset_type, split_type):\n    \"\"\"\n    Función que limpia un DataFrame eliminando valores nulos y redirige a la limpieza específica según el tipo de dataset.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que se desea limpiar.\n        dataset_type (str): Tipo de dataset, debe ser 'MELD' o 'MOSEI'.\n        split_type (str): Tipo de partición del dataset ('train', 'dev', 'test').\n\n    Returns:\n        pandas.DataFrame: DataFrame limpio, procesado según las reglas específicas del dataset indicado.\n\n    Raises:\n        ValueError: Si el tipo de dataset no es 'MELD' ni 'MOSEI'.\n    \"\"\"\n    # Se eliminan las filas con cualquier valor nulo\n    df.replace('', pd.NA, inplace = True)\n    df.dropna(inplace = True)\n\n    # Se redirecciona a la limpieza pertinente\n    if dataset_type == 'MELD':\n        input_path = DATASET_PATHS.get(dataset_type)\n        return clean_MELD_dfs(df, split_type, input_path)\n\n    elif dataset_type == 'MOSEI':\n        input_path = DATASET_PATHS.get(dataset_type + '_audios')\n        return clean_MOSEI_dfs(df, input_path)\n\n    else:\n        raise ValueError(\"dataset_type debe ser 'MELD' o 'MOSEI'\")\n\ndef clean_MELD_dfs(df, split_type, input_path):\n    \"\"\"\n    Función que limpia y transforma un DataFrame del dataset MELD, eliminando columnas innecesarias, renombrando variables,\n    generando rutas de video y convirtiendo columnas de tiempo a segundos.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del dataset MELD que se desea procesar.\n        split_type (str): Tipo de partición ('train' o 'dev'), utilizado para construir la ruta a los archivos de video.\n        input_path (str): Ruta base del dataset MELD.\n\n    Returns:\n        pandas.DataFrame: DataFrame transformado con las columnas relevantes, rutas de video y tiempos en formato numérico.\n\n    Raises:\n        ValueError: Si `split_type` no es 'train' ni 'dev'.\n    \"\"\"\n    # Se eliminan las columnas innecesarias\n    df = df.drop(columns = ['Sr No.', 'Speaker', 'Episode'])\n\n    # Se renombra la columna 'Utterance' como 'text'\n    df = df.rename(columns={'Utterance': 'text', 'Sentiment': 'sentiment'})\n    \n    # Extensión del path según el dataframe\n    if split_type == 'train':\n        video_folder = 'train/train_splits/dia'\n    elif split_type == 'dev':\n        video_folder = 'dev/dev_splits_complete/dia'\n    else:\n        raise ValueError(\"split_type debe ser 'train' o 'dev' para MELD\")\n\n    # Se construye la columna 'video_path'\n    df['video_path'] = (\n        input_path + \n        video_folder + \n        df['Dialogue_ID'].astype(str) + '_utt' + \n        df['Utterance_ID'].astype(str) + '.mp4')\n\n    # Se convierten las columnas de tiempo en formato numérico (segundos)\n    df = convert_time_columns_MELD(df)\n    return df\n\ndef clean_MOSEI_dfs(df, input_path):\n    \"\"\"\n    Función que limpia y transforma un DataFrame del dataset MOSEI, eliminando columnas no relevantes, generando variables auxiliares\n    y construyendo las rutas de acceso a archivos de audio.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del dataset MOSEI que se desea procesar.\n        input_path (str): Ruta base donde se encuentran los archivos de audio.\n\n    Returns:\n        pandas.DataFrame: DataFrame transformado con las columnas necesarias y nuevas variables generadas.\n    \"\"\"\n    # Se eliminan las columnas innecesarias\n    df = df.drop(columns = ['ASR'])\n    \n    # Se crea la columna 'neutral' basada en otras emociones\n    emotion_cols = ['happy', 'sad', 'anger', 'surprise', 'disgust', 'fear']\n    df['neutral'] = df[emotion_cols].sum(axis = 1).apply(lambda x: 3 if x == 0 else 0)\n\n    # Construcción de las columnas 'video_path' y 'audio_name'\n    df['video_path'] = (\n        input_path + df['video'].astype(str) + '.wav'\n    )\n    df['audio_name'] = (\n        df['video'].astype(str) + '_' + df['start_time'].astype(str) + '_' + df['end_time'].astype(str) + '.wav'\n    )\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.374189Z","iopub.execute_input":"2025-04-13T19:08:01.374514Z","iopub.status.idle":"2025-04-13T19:08:01.394522Z","shell.execute_reply.started":"2025-04-13T19:08:01.374475Z","shell.execute_reply":"2025-04-13T19:08:01.393645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_empty_text_rows(df):\n    \"\"\"\n    Función que identifica y muestra la cantidad de filas con textos vacíos o nulos en un DataFrame, y devuelve dichas filas.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a evaluar.\n\n    Returns:\n        pandas.DataFrame: Subconjunto del DataFrame original que contiene las filas con textos vacíos o valores nulos.\n\n    Notes:\n        Se imprime por consola el número de textos vacíos, nulos y el total de casos problemáticos detectados.\n    \"\"\"\n    # Se detectan y cuentan las filas con textos vacíos\n    empty_mask = df['text'].astype(str).str.strip() == ''\n    num_empty = empty_mask.sum()\n\n    # Se cuentan las filas con textos nulos\n    num_null = df['text'].isnull().sum()\n\n    # Se muestra un mensaje con el número de filas con textos vacíos por tipo y el total\n    print(f\"Textos vacíos (solo espacios o ''): {num_empty}\")\n    print(f\"Textos nulos (NaN): {num_null}\")\n    print(f\"Total de textos problemáticos: {num_empty + num_null}\")\n\n    # Se devuleven las filas con textos vacíos\n    return df[empty_mask | df['text'].isnull()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.395517Z","iopub.execute_input":"2025-04-13T19:08:01.395839Z","iopub.status.idle":"2025-04-13T19:08:01.414453Z","shell.execute_reply.started":"2025-04-13T19:08:01.395819Z","shell.execute_reply":"2025-04-13T19:08:01.413646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_empty_text_rows(df, name_df):\n    \"\"\"\n    Función que elimina las filas con textos vacíos en la columna 'text' de un DataFrame y muestra un resumen de la operación.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del que se desean eliminar las filas con texto vacío.\n        name_df (str): Nombre del DataFrame.\n\n    Returns:\n        pandas.DataFrame: DataFrame resultante tras eliminar las filas con textos vacíos.\n    \"\"\"\n    # Se calcula el número de filas original del dataframe\n    original_len = len(df)\n\n    # Se eliminan las filas cuyo texto esté vacío\n    df = df[df['text'].astype(str).str.strip() != '']\n\n    # Se calcula el número de filas final del dataframe y se muestra el mensaje\n    final_len = len(df)\n    print(f\"Se han eliminado {original_len - final_len} filas con texto vacío. {name_df} ahora tiene un shape {df.shape}\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.415229Z","iopub.execute_input":"2025-04-13T19:08:01.415506Z","iopub.status.idle":"2025-04-13T19:08:01.427552Z","shell.execute_reply.started":"2025-04-13T19:08:01.415485Z","shell.execute_reply":"2025-04-13T19:08:01.426870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Adecuación de las columnas de los CSVs","metadata":{}},{"cell_type":"code","source":"def normalize_emotion_and_sentiment(df, dataset_type):\n    \"\"\"\n    Función que normaliza las etiquetas de sentimiento y emociones en un DataFrame, adaptándolas según el tipo de dataset.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene las columnas de sentimiento y emociones a normalizar.\n        dataset_type (str): Tipo de dataset al que pertenece el DataFrame ('MELD' o 'MOSEI').\n\n    Returns:\n        tuple:\n            pandas.DataFrame: DataFrame con las etiquetas de sentimiento y emociones normalizadas.\n            dict or None: Diccionario de mapeo de emociones usado en MELD, o None si no aplica.\n\n    Notes:\n        Se invoca `classify_sentiment` para estandarizar la columna de sentimiento y `normalize_emotions` para adaptar\n        las emociones según el dataset. Si se trata de MELD, se imprime el diccionario de emociones transformadas.\n    \"\"\"\n    # Normalización de la columna Sentiment\n    df = classify_sentiment(df, dataset_type)\n    \n    # Normalización y adecuación de las columnas de emociones\n    df, emotion_dict_MELD = normalize_emotions(df, dataset_type)\n\n    # Print de la adecuación de las emociones de MELD\n    if emotion_dict_MELD:\n        print(\"Emociones en MELD:\", emotion_dict_MELD)\n\n    return df, emotion_dict_MELD if emotion_dict_MELD else None\n\n\ndef classify_sentiment(df, dataset_type):\n    \"\"\"\n    Función que clasifica y normaliza los valores de la columna 'sentiment' en un DataFrame, asignando clases numéricas según el tipo de dataset.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene la columna 'sentiment' con valores categóricos (MELD) o numéricos (MOSEI).\n        dataset_type (str): Tipo de dataset ('MELD' o 'MOSEI') que determina el esquema de codificación a utilizar.\n\n    Returns:\n        pandas.DataFrame: DataFrame con la columna 'sentiment' convertida a clases numéricas: 0 (negativo), 1 (neutral), 2 (positivo).\n\n    Notes:\n        - Para MELD, se mapean las categorías de texto ('negative', 'neutral', 'positive') a enteros.\n        - Para MOSEI, los valores numéricos se agrupan en tres clases en función de su signo.\n    \"\"\"\n    if dataset_type == 'MELD':\n        # Se mapean los sentimentos de MELD a 3 clases\n        sentiment_map_MELD = {'negative': 0, 'neutral': 1, 'positive': 2}\n        # Se sustituyen los valores categóricos de la columna sentiment por valores numéricos\n        df['sentiment'] = df['sentiment'].map(sentiment_map_MELD)\n\n    elif dataset_type == 'MOSEI':\n        # Se define una sub-función para clasificar el sentimiento de MOSEI\n        def sentiment_map_MOSEI(value):\n            # Si el valor es negativo, será la clase 0\n            if value < 0:\n                return 0\n            # Si el valor es neutral, será la clase 1\n            elif value == 0:\n                return 1\n            # Si el valor es positivo, será la clase 2\n            else:\n                return 2\n        # Se aplica el cambio del sentimiento a clases\n        df.loc[:, 'sentiment'] = df['sentiment'].apply(sentiment_map_MOSEI)\n\n    return df\n    \n\ndef normalize_emotions(df, dataset_type):\n    \"\"\"\n    Función que normaliza las emociones en un DataFrame según el tipo de dataset, aplicando codificación numérica o escalado.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene las emociones a procesar.\n        dataset_type (str): Tipo de dataset ('MELD' o 'MOSEI') que determina el tipo de normalización aplicada.\n\n    Returns:\n        tuple:\n            pandas.DataFrame: DataFrame con las emociones normalizadas.\n            dict or None: Diccionario de codificación de emociones utilizado (solo para MELD), o None si no aplica.\n\n    Notes:\n        - Para MELD, se reemplazan los valores categóricos de la columna 'Emotion' por valores numéricos entre 0 y 6.\n        - Para MOSEI, cada columna de emoción ('happy', 'sad', etc.) se escala entre 0.0 y 1.0 usando normalización min-max, redondeada a un decimal.\n    \"\"\"\n    # Definición del diccionario de emociones para MELD\n    emotion_dict_MELD = None\n\n    if dataset_type == 'MELD':\n        # Lista de emociones de MELD\n        emotions = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n        emotion_dict_MELD = {emotion: i for i, emotion in enumerate(emotions)}\n\n        # Se reemplazan los valores categóricos de la columna Emotion por valores numéricos\n        df['Emotion'] = df['Emotion'].map(emotion_dict_MELD)\n\n    elif dataset_type == 'MOSEI':\n        # Lista de emociones de MOSEI\n        emotions = ['happy', 'sad', 'anger', 'surprise', 'disgust', 'fear', 'neutral']\n        # Por cada emoción, se normaliza su columna\n        for emotion in emotions:\n            min_val = df[emotion].min()\n            max_val = df[emotion].max()\n            range_val = max_val - min_val\n            df[emotion] = round((df[emotion] - min_val) / range_val, 1) if range_val != 0 else 0.0\n\n    return df, emotion_dict_MELD\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.428359Z","iopub.execute_input":"2025-04-13T19:08:01.428659Z","iopub.status.idle":"2025-04-13T19:08:01.457839Z","shell.execute_reply.started":"2025-04-13T19:08:01.428633Z","shell.execute_reply":"2025-04-13T19:08:01.457051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocesamiento del dataset","metadata":{}},{"cell_type":"markdown","source":"### Preprocesamiento del texto","metadata":{}},{"cell_type":"markdown","source":"#### Preprocesamiento básico","metadata":{}},{"cell_type":"code","source":"def preprocess_text_column(df):\n    \"\"\"\n    Función que aplica las transformaciones de preprocesamiento sobre la columna 'text' de un DataFrame.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a preprocesar.\n\n    Returns:\n        pandas.DataFrame: DataFrame con la columna 'text' transformada tras aplicar limpieza y normalización textual.\n\n    Notes:\n        Las transformaciones aplicadas incluyen:\n        - Conversión del texto a minúsculas.\n        - Eliminación de repeticiones de letras y onomatopeyas.\n        - Eliminación de símbolos extraños.\n        - Expansión de contracciones.\n        - Eliminación de signos de puntuación.\n    \"\"\"\n    # Se pone el texto en minúsculas\n    df['text'] = df['text'].apply(lambda x: x.lower())\n\n    # Se limpian las palabras repetidas y las onomotopeyas\n    df['text'] = df['text'].apply(clean_repetitions_and_sounds)      \n\n    # Se eliminan los símbolos extraños\n    df['text'] = df['text'].apply(remove_symbols)\n\n    # Se expanden las contracciones\n    df['text'] = df['text'].apply(expand_contractions)\n\n    # Se eliminan los símbolos de puntuación\n    df['text'] = df['text'].apply(remove_punctuation)\n\n    return df\n\ndef clean_repetitions_and_sounds(text):\n    \"\"\"\n    Función que limpia repeticiones innecesarias de palabras y elimina onomatopeyas o sonidos entre paréntesis en un texto.\n\n    Args:\n        text (str): Cadena de texto que se desea limpiar.\n\n    Returns:\n        str: Texto procesado, sin repeticiones consecutivas ni sonidos escritos entre paréntesis.\n    \"\"\"\n    # Se cambian repeticiones por una única palabra (ex: \"hey-hey-hey\" -> \"hey\")\n    text = re.sub(r'\\b(\\w+)(-\\1)+\\b', r'\\1', text)\n    \n    # Se cambian repeticiones por una única palabra (ex: \"hey hey hey\" -> \"hey\")\n    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n\n    # Se eliminan las onomatopeyas y sonidos entre paréntesis (ex: (uhh), (stutter))\n    text = re.sub(r'\\(\\s*[^)]+\\s*\\)', '', text)\n\n    # Se eliminan los espacios duplicados creados después de limpiar\n    text = re.sub(r'\\s{2,}', ' ', text).strip()\n    return text\n\n\ndef remove_symbols(text):\n    \"\"\"\n    Función que elimina caracteres no ASCII de una cadena de texto.\n\n    Args:\n        text (str): Cadena de texto a procesar.\n\n    Returns:\n        str: Texto resultante sin símbolos ni caracteres especiales fuera del rango ASCII estándar.\n    \"\"\"\n    # Se eliminan los caracteres no ASCII\n    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n    return text\n\n\ndef expand_contractions(text):\n    \"\"\"\n    Función que expande las contracciones en inglés presentes en una cadena de texto.\n\n    Args:\n        text (str): Cadena de texto que puede contener contracciones del inglés.\n\n    Returns:\n        str: Texto con las contracciones expandidas a su forma completa.\n\n    Notes:\n        Utiliza la librería `contractions` para convertir las expresiones.\n    \"\"\"\n    # Se expanden las contracciones inglesas (ex: they're -> they are)\n    return contractions.fix(text)\n\n\ndef remove_punctuation(text):\n    \"\"\"\n    Función que elimina los signos de puntuación de una cadena de texto y corrige los espacios sobrantes.\n\n    Args:\n        text (str): Cadena de texto que se desea limpiar.\n\n    Returns:\n        str: Texto sin signos de puntuación ni espacios duplicados.\n\n    Notes:\n        Se eliminan todos los caracteres definidos en `string.punctuation`.\n    \"\"\"\n    # Se eliminan los símbolos de puntuación\n    translator = str.maketrans('', '', string.punctuation)\n    text = text.translate(translator)\n\n    # Se eliminan los espacios duplicados creados después de limpiar\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.459878Z","iopub.execute_input":"2025-04-13T19:08:01.460115Z","iopub.status.idle":"2025-04-13T19:08:01.475202Z","shell.execute_reply.started":"2025-04-13T19:08:01.460098Z","shell.execute_reply":"2025-04-13T19:08:01.474439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Stopwords en formato n-gramas y unitarias","metadata":{}},{"cell_type":"code","source":"''' N-GRAMAS DE TIPO STOPWORD'''\n\ndef load_texts_from_dfs(dfs):\n    \"\"\"\n    Función que extrae y concatena todos los textos no nulos de la columna 'text' a partir de una lista de DataFrames.\n\n    Args:\n        dfs (list of pandas.DataFrame): Lista de DataFrames.\n\n    Returns:\n        list of str: Lista de cadenas de texto resultantes, convertidas a tipo `str` y excluyendo los valores nulos.\n    \"\"\"\n    # Se concatenan todos los textos disponibles\n    return [str(row) for df in dfs for row in df['text'].dropna()]\n\ndef clean_and_tokenize(text):\n    \"\"\"\n    Función que tokeniza un texto eliminando los símbolos y conservando únicamente las palabras que estén en una lista de 'stop_words'.\n\n    Args:\n        text (str): Cadena de texto que se desea tokenizar y filtrar.\n\n    Returns:\n        str: Cadena de texto reconstruida a partir de las palabras reconocidas como 'stop_words'.\n    \"\"\"\n    # Sokenizan las palabras sin simbolos\n    tokens = re.findall(r'\\b\\w+\\b', text)\n    return ' '.join([token for token in tokens if token in stop_words])\n\ndef extract_stopword_ngrams_corpus(corpus, min_df = 5, ngram_range = (2, 6)):\n    \"\"\"\n    Función que extrae n-gramas compuestos únicamente por 'stopwords' desde un corpus textual.\n\n    Args:\n        corpus (list of str): Lista de cadenas de texto que componen el corpus.\n        min_df (int, optional): Frecuencia mínima con la que un n-grama debe aparecer para ser considerado. Por defecto es 5.\n        ngram_range (tuple of int, optional): Rango de tamaño de los n-gramas a extraer (mínimo, máximo). Por defecto es (2, 6).\n\n    Returns:\n        list of str: Lista de n-gramas ordenados de mayor a menor según la cantidad de palabras que los componen.\n\n    Notes:\n        - Se utiliza la función `clean_and_tokenize` para generar un corpus filtrado que conserve solo 'stopwords'.\n        - Los n-gramas se extraen mediante `CountVectorizer` de scikit-learn.\n        - Los n-gramas que no cumplen con el umbral de frecuencia `min_df` son descartados.\n    \"\"\"\n    # Se crea el corpus limpio sin símbolos\n    cleaned_corpus = [clean_and_tokenize(text) for text in corpus]\n\n    # Se vectorizan los n-gramas para quedarnos aquellos se repitan un mínimos de veces en el df\n    vectorizer = CountVectorizer(ngram_range = ngram_range, min_df = min_df)\n    X = vectorizer.fit_transform(cleaned_corpus)\n    ngram_freq = vectorizer.vocabulary_\n\n    # Se ordenanan los n-gramas de mayor a menor número de palabras\n    sorted_ngrams = sorted(ngram_freq.keys(), \n                           key = lambda x: -len(x.split()))\n    return sorted_ngrams\n\ndef save_stopword_ngrams_corpus(ngrams):\n    \"\"\"\n    Función que guarda en un archivo JSON la lista de n-gramas formados únicamente por 'stopwords'.\n\n    Args:\n        ngrams (list of str): Lista de n-gramas que se desea almacenar.\n\n    Returns:\n        None: La función no retorna ningún valor. El resultado se guarda en el archivo 'stopword_ngrams.json'.\n\n    \"\"\"\n    # Se guarda la lista de n-gramas de tipo stopword en un fichero json para ser reutilizado\n    with open(\"stopword_ngrams.json\", 'w') as f:\n        json.dump(ngrams, f, indent = 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.475971Z","iopub.execute_input":"2025-04-13T19:08:01.476182Z","iopub.status.idle":"2025-04-13T19:08:01.496921Z","shell.execute_reply.started":"2025-04-13T19:08:01.476166Z","shell.execute_reply":"2025-04-13T19:08:01.496286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_stopword_ngrams_from_dfs(df, stopword_ngrams, max_ngram_len, name_df):\n    \"\"\"\n    Función que elimina n-gramas compuestos únicamente por 'stopwords' de la columna 'text' de un DataFrame.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a limpiar.\n        stopword_ngrams (list of str): Lista de n-gramas de tipo 'stopword' que deben eliminarse.\n        max_ngram_len (int): Longitud máxima de los n-gramas considerados durante la limpieza.\n        name_df (str): Nombre identificador del DataFrame.\n\n    Returns:\n        pandas.DataFrame: DataFrame con la columna 'text' limpia y sin n-gramas de tipo 'stopword'. \n        También se eliminan las filas con texto vacío resultante tras el proceso.\n\n    Notes:\n        - El proceso recorre cada texto tokenizado, evaluando posibles coincidencias con los n-gramas proporcionados, desde el más largo al más corto.\n        - Cuando se detecta un n-grama en el texto, se eliminan todos los tokens que lo componen.\n        - Se utiliza la función `remove_empty_text_rows` para descartar filas que quedan vacías tras la limpieza.\n    \"\"\"\n    # Se define una sub-función para limpiar cada texto\n    def clean_text(text):\n        # Se tokeniza el texto\n        tokens = text.split()\n\n        # Se definen las variables auxiliares\n        keep = [True] * len(tokens)\n        i = 0\n\n        # Mientras no se hayan estudiado toda la frase al completo\n        while i < len(tokens):\n            matched = False\n            # Se recorre desde el n-grama más largo hasta los bigramas\n            for n in range(min(max_ngram_len, len(tokens) - i), 1, -1):\n                # Se define el n-grama a estudiar\n                ngram = ' '.join(tokens[i:i+n])\n                # Si este n-grama está contenido en lso n-gramas de tipo stopword,\n                # se mantiene la frase que sigue después del n-grama\n                if ngram in stopword_ngrams:\n                    for j in range(i, i+n):\n                        keep[j] = False\n                    i += n\n                    matched = True\n                    break\n            # Si no hay ningún match con los ngramas, seguimos estudiando el texto\n            if not matched:\n                i += 1\n\n        # Se reconstruye el texto con las palabras que no son stopwords\n        cleaned = ' '.join([tok for tok, keep_flag in zip(tokens, keep) if keep_flag])\n        \n        # Se devuelve el texto limpio\n        return cleaned\n\n    # Se aplica la limpieza a la columna de texto\n    df['text'] = df['text'].astype(str).apply(clean_text)\n\n    # Se eliminan las filas con texto vacío después de quitar los n-gramas de tipo stopword\n    return remove_empty_text_rows(df, name_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:08:01.497779Z","iopub.execute_input":"2025-04-13T19:08:01.498160Z","iopub.status.idle":"2025-04-13T19:08:01.516612Z","shell.execute_reply.started":"2025-04-13T19:08:01.498133Z","shell.execute_reply":"2025-04-13T19:08:01.515902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"''' STOPWORDS UNITARIAS '''\ndef remove_stopwords_single_from_dfs(df, name_df):\n    \"\"\"\n    Función que elimina las 'stopwords' individuales de la columna 'text' de un DataFrame.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a limpiar.\n        name_df (str): Nombre identificador del DataFrame.\n\n    Returns:\n        pandas.DataFrame: DataFrame con la columna 'text' sin 'stopwords', y sin filas con texto vacío tras el proceso.\n\n    Notes:\n        - Las 'stopwords' se definen mediante la lista `stop_words` de NLTK.\n        - Cada texto se tokeniza por espacios y se reconstruye excluyendo los tokens presentes en 'stopwords'.\n        - Se llama a `remove_empty_text_rows` para eliminar filas que resulten vacías después de la limpieza.\n    \"\"\"\n    # Se define una sub-función para limpiar cada texto\n    def remove_stopwords(text):\n        # Se tokeniza el texto\n        tokens = text.split()\n\n        # Se eliminan las stopwords de NLTK encontradas en el texto\n        cleaned_tokens = [token for token in tokens if token not in stop_words]\n\n        # Se devuelve el texto limpio\n        return ' '.join(cleaned_tokens)\n\n    # Se aplica la limpieza a la columna de texto \n    df.loc[:, 'text'] = df['text'].apply(remove_stopwords)\n\n    # Se eliminan las filas con texto vacío después de quitar las stopwords\n    return remove_empty_text_rows(df, name_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generación del dataframe MELD para test","metadata":{}},{"cell_type":"code","source":"def get_meld_test(df_train, test_size):\n    \"\"\"\n    Función que genera o carga un conjunto de test a partir del dataset MELD, utilizando un `train_test_split` persistente en disco.\n\n    Args:\n        df_train (pandas.DataFrame): DataFrame original de entrenamiento del dataset MELD.\n        test_size (float): Proporción del dataset que se desea utilizar como conjunto de prueba (entre 0 y 1).\n\n    Returns:\n        tuple:\n            pandas.DataFrame: Subconjunto de entrenamiento tras la partición.\n            pandas.DataFrame: Subconjunto de prueba.\n\n    Notes:\n        - Si existen los archivos `initial_MELD_train.csv` y `initial_MELD_test.csv`, se cargan directamente desde disco.\n        - En caso contrario, se realiza la partición mediante `train_test_split` de scikit-learn y se guardan ambos subconjuntos en disco para uso futuro.\n    \"\"\"\n    train_path = \"initial_MELD_train.csv\"\n    test_path = \"initial_MELD_test.csv\"\n\n    if os.path.exists(train_path) and os.path.exists(test_path):\n        print(\"Cargando splits ya existentes...\")\n        # Se cargan los splits ya realizados previamente            \n        df_train_split = pd.read_csv(train_path)\n        df_test = pd.read_csv(test_path)\n    else:\n        print(\"Se generarán y guardarán los splits...\")\n        # Se realiza un train-test split para conseguir un dataframe de test para MELD\n        df_train_split, df_test = train_test_split(df_train, test_size = test_size, random_state = 42)\n    \n        # Guardamos ambos dataset en ficheros CSV\n        df_train_split.to_csv(train_path, index = False)\n        df_test.to_csv(test_path, index = False)\n    \n    # Se devuleven los dataframes resultantes\n    return df_train_split, df_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def filter_short_texts(df, name_df, min_words = 5):\n    \"\"\"\n    Función que elimina del DataFrame las filas cuya columna 'text' contenga menos de un número mínimo de palabras.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a evaluar.\n        name_df (str): Nombre identificador del DataFrame\n        min_words (int, optional): Número mínimo de palabras requerido para conservar una fila. Por defecto es 5.\n\n    Returns:\n        pandas.DataFrame: DataFrame filtrado, sin filas cuyo texto tenga menos de `min_words` palabras.\n\n    Notes:\n        - Esta función es útil para eliminar muestras consideradas ruidosas o poco informativas en tareas de modelaje.\n        - Imprime por consola el número de filas antes y después del filtrado.\n    \"\"\"\n    # Se calcula el número de filas original del dataframe\n    original_len = len(df)\n    \n    # Se eliminan las muestras que tengan menos de 'min_words' palabras por generar ruido en las predicciones\n    df = df[df['text'].apply(lambda x: len(str(x).split()) >= min_words)].reset_index()\n\n    # Se calcula el número de filas final del dataframe y se muestra el mensaje\n    final_len = len(df)\n    print(f\"{name_df} pasa de {original_len} filas a tener {final_len} filas.\")\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Feature Engineering","metadata":{}},{"cell_type":"code","source":"def add_polarity_and_subjectivity(df):\n    \"\"\"\n    Función que añade al DataFrame dos nuevas columnas con las métricas de polaridad y subjetividad calculadas a partir de la columna 'text'.\n\n    Args:\n        df (pandas.DataFrame): DataFrame a analizar.\n\n    Returns:\n        pandas.DataFrame: DataFrame con dos columnas adicionales:\n            - 'polarity': Valor de polaridad del texto (entre -1.0 y 1.0).\n            - 'subjectivity': Valor de subjetividad del texto (entre 0.0 y 1.0).\n\n    Notes:\n        - Se utiliza la librería `TextBlob` para el cálculo.\n        - La polaridad indica cuán positivo o negativo es un texto.\n        - La subjetividad mide el grado de opinión personal o juicio (más cercano a 1.0) frente a hechos objetivos (más cercano a 0.0).\n    \"\"\"\n    # Se deninen las variables base\n    polarities = []\n    subjectivities = []\n\n    # Por cada texto, se define su polaridad y su subjetividad\n    for text in df['text']:\n        blob = TextBlob(str(text))\n        polarities.append(blob.sentiment.polarity)\n        subjectivities.append(blob.sentiment.subjectivity)\n\n    # Se añaden ambas variables como columnas del dataframe\n    df['polarity'] = polarities\n    df['subjectivity'] = subjectivities\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def feature_engineering_MELD(df):\n    \"\"\"\n    Función que genera y normaliza variables derivadas para el dataset MELD para el posterior modelaje.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del dataset MELD que contiene las columnas necesarias para el cálculo de nuevas características.\n\n    Returns:\n        pandas.DataFrame: DataFrame extendido con nuevas columnas.\n\n    Notes:\n        Las siguientes variables son generadas o transformadas:\n        - 'duration': Diferencia entre 'EndTime_sec' y 'StartTime_sec', indicando la duración del clip.\n        - 'turn_position': Posición relativa del turno dentro del diálogo, normalizada.\n        - 'dialogue_id_norm': Valor de 'Dialogue_ID' normalizado.\n        - 'utterance_id_norm': Valor de 'Utterance_ID' normalizado.\n        - 'season_norm': Valor de 'Season' normalizado.\n        - 'polarity' y 'subjectivity': Métricas lingüísticas extraídas mediante `TextBlob`.\n\n        La función opera sobre una copia del DataFrame original para evitar efectos colaterales.\n    \"\"\"\n    df = df.copy()\n\n    # Se define las variables:\n    # 'duration' como la duración del texto al ser hablado\n    df['duration'] = df['EndTime_sec'] - df['StartTime_sec']\n\n    # 'turn_position' como la posición del turno normalizada en el diálogo\n    df['turn_position'] = df['Utterance_ID'] / df.groupby('Dialogue_ID')['Utterance_ID'].transform('max')\n\n    # Normalización de las variables 'Dialogue_ID', 'Utterance_ID' y 'Season'\n    df['dialogue_id_norm'] = df['Dialogue_ID'] / df['Dialogue_ID'].max()\n    df['utterance_id_norm'] = df['Utterance_ID'] / df['Utterance_ID'].max()\n    df['season_norm'] = df['Season'] / df['Season'].max()\n\n    # 'polarity' y 'subjectivity'\n    df = add_polarity_and_subjectivity(df)\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def feature_engineering_MOSEI(df):\n    \"\"\"\n    Función que genera y normaliza variables derivadas para el dataset MOSEI para el posterior modelaje.\n\n    Args:\n        df (pandas.DataFrame): DataFrame del dataset MOSEI con las columnas necesarias para el cálculo de nuevas características.\n\n    Returns:\n        pandas.DataFrame: DataFrame extendido con nuevas columnas.\n\n    Notes:\n        Las siguientes variables son generadas o transformadas:\n        - 'duration': Diferencia entre 'end_time' y 'start_time', indicando la duración del clip.\n        - 'intensity': Suma total de la activación emocional entre todas las emociones.\n        - 'dominant_emotion': Emoción con mayor valor en la fila.\n        - 'positive_emotions': Número de emociones con valor positivo (> 0).\n        - 'negative_emotions': Número de emociones con valor negativo (< 0).\n        - 'polarity' y 'subjectivity': Métricas lingüísticas extraídas mediante `TextBlob`.\n\n        La función opera sobre una copia del DataFrame original para evitar efectos colaterales.\n    \"\"\"\n    df = df.copy()\n\n    # Se define las variables:\n    # 'duration' como la duración del texto al ser hablado\n    df['duration'] = df['end_time'] - df['start_time']\n\n    # 'intensity' como la intensidad emocional total de sumar todas las emociones\n    emotion_cols = ['happy', 'sad', 'anger', 'surprise', 'disgust', 'fear', 'neutral']\n    df['intensity'] = df[emotion_cols].sum(axis = 1)\n\n    # 'dominant_emotion' como el ID de la primera emoción con mayor valor\n    df['dominant_emotion'] = df[emotion_cols].idxmax(axis = 1)\n\n    # Se define el diccionario de emociones de MOSEI\n    emotions = ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n    emotion_dict_MOSEI = {emotion: i for i, emotion in enumerate(emotions)}\n\n    # Se reemplazan los valores categóricos de la columna 'dominant_emotion' por valores numéricos\n    df['dominant_emotion'] = df['dominant_emotion'].map(emotion_dict_MOSEI)\n\n    # 'positive_emotions' como el número de emociones con valor positivo\n    df['positive_emotions'] = df[emotion_cols].gt(0).sum(axis = 1)\n\n    # 'positive_emotions' como el número de emociones con valor positivo\n    df['negative_emotions'] = df[emotion_cols].lt(0).sum(axis = 1)\n\n    # 'polarity' y 'subjectivity'\n    df = add_polarity_and_subjectivity(df)\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Preprocesamiento del audio","metadata":{}},{"cell_type":"markdown","source":"#### Espectrogramas de Mel","metadata":{}},{"cell_type":"code","source":"def create_mel_spectrograms_ffmpeg(df, output_folder, sr = 16000, n_mels = 128, fixed_duration = 4.0, target_shape = (224, 224)):\n    \"\"\"\n    Función que genera espectrogramas de Mel a partir de archivos de audio o video usando `ffmpeg` y `librosa`, \n    y los guarda como archivos `.npy`.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene la columna 'video_path' y, en el caso de MOSEI, también 'start_time', 'end_time' y 'audio_name'.\n        output_folder (str): Carpeta donde se guardarán los archivos `.npy` con los espectrogramas.\n        sr (int, optional): Frecuencia de muestreo objetivo en Hz. Por defecto es 16000.\n        n_mels (int, optional): Número de bandas Mel que se utilizarán. Por defecto es 128.\n        fixed_duration (float, optional): Duración fija del audio en segundos para normalizar la longitud de entrada. Por defecto es 4.0 segundos.\n        target_shape (tuple of int, optional): Dimensiones objetivo del espectrograma (alto, ancho). Por defecto es (224, 224).\n\n    Returns:\n        pandas.DataFrame: DataFrame original con una nueva columna 'mel_path', que contiene la ruta a cada espectrograma generado.\n\n    Notes:\n        - Para registros MOSEI, se recorta el fragmento de audio entre 'start_time' y 'end_time' usando `ffmpeg`.\n        - Para MELD, se procesa directamente el archivo completo.\n        - Los audios cortos se rellenan con ceros y los audios largos se recortan a `fixed_duration`.\n        - Se aplica un escalado para ajustar el tamaño del espectrograma a `target_shape` mediante interpolación con `scipy.ndimage.zoom`.\n        - Los espectrogramas se guardan como archivos `.npy` y se almacenan sus rutas en la columna 'mel_path'.\n        - En caso de error o audio vacío, se imprime una advertencia y se asigna `None` en la columna correspondiente.\n    \"\"\"\n    # Se crea el path final de los espectrogramas si no existe\n    os.makedirs(output_folder, exist_ok = True)\n\n    # Se define la lista de paths para los espectrogramas de Mel\n    mel_paths = []\n\n    # Por cada video o audio registrado en el dataframe\n    for idx, row in tqdm(df.iterrows(), total = len(df)):\n        # Extraemos el path del video o audio\n        video_path = row['video_path']\n        \n        if 'audio_name' in df.columns:\n            file_id = row['audio_name']\n        else:\n            file_id = os.path.splitext(os.path.basename(video_path))[0]\n\n\n        # Definimos el path final del espetrograma como la carpeta del dataset y el nombre del video o audio\n        output_path = os.path.join(output_folder, f\"{file_id}.npy\")\n\n        try:\n            if 'audio_name' in df.columns:\n                # Caso MOSEI: se carga solo el fragmento necesario del audio original\n                start_time = row['start_time']\n                end_time = row['end_time']\n\n                # Se extrae el audio entre start_time y end_time\n                out, _ = (\n                    ffmpeg\n                    .input(video_path, ss = start_time, t = (end_time - start_time))\n                    .output('pipe:', format = 'wav', ac = 1, ar = sr)\n                    .run(capture_stdout=True, capture_stderr=True)\n                )\n            else:\n                # Caso MELD: se carga todo el audio del video al estar previamente cortado\n                out, _ = (\n                    ffmpeg\n                    .input(video_path)\n                    .output('pipe:', format = 'wav', ac = 1, ar = sr)\n                    .run(capture_stdout=True, capture_stderr=True)\n                )\n\n            # Se intenta cargar el audio extraido\n            y, _ = librosa.load(io.BytesIO(out), sr = sr)\n\n            # En el caso de que el audio esté corrupto o vacío\n            if y is None or len(y) == 0:\n                # No añadimos ningún path y saltamos a la siguiente pista de audio\n                print(f\"Audio vacío en {video_path}. Saltando.\")\n                mel_paths.append(None)\n                continue\n\n            # En el caso de que sí haya audio, este se ajusta al fixed_duration establecido\n            # Primero, se calcula el largo esperado\n            target_length = int(sr * fixed_duration)\n\n            # Si la pista de audio es más pequeña que el target\n            if len(y) < target_length:\n                # Se rellena con ceros el tramo faltante, simulando silencio\n                padding = target_length - len(y)\n                y = np.pad(y, (0, padding), mode = 'constant')\n            else:\n                # Si es más largo que lo fijado, se recorta\n                y = y[:target_length]\n\n            # Se crea el Espectrograma de Mel\n            S = librosa.feature.melspectrogram(y = y, sr = sr, n_mels = n_mels)\n            S_db = librosa.power_to_db(S, ref = np.max)\n\n            # Se ajusta el tamaño del espectrograma al tamaño común establecido target_shape\n            zoom_factors = (target_shape[0] / S_db.shape[0], target_shape[1] / S_db.shape[1])\n            S_db_resized = zoom(S_db, zoom_factors)\n\n            # Se guarda el Espectrograma de Mel y se añade el path de este a la lista\n            np.save(output_path, S_db_resized)\n            mel_paths.append(output_path)\n\n        except Exception as e:\n            # En el caso de algún error al procesar los espectrogramas de Mel, se muestra por pantalla\n            print(f\"Error procesando {video_path}: {e}\")\n            mel_paths.append(None)\n\n    # Se crea la columna mel_path con los paths a los respectivos Espectrogramas de Mel de cada video o audio\n    df['mel_path'] = mel_paths\n\n    # Se devuelve el dataframe actualizado\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_df_or_create_mel_spectrograms(df_audio, output_folder, csv_path):\n    \"\"\"\n    Función que carga un DataFrame con rutas a espectrogramas de Mel si el archivo CSV ya existe, o los genera desde cero en caso contrario.\n\n    Args:\n        df_audio (pandas.DataFrame): DataFrame que contiene la columna 'video_path' (y opcionalmente 'start_time', 'end_time', 'audio_name' en MOSEI) usada para generar los espectrogramas.\n        output_folder (str): Carpeta de destino donde se guardarán los archivos `.npy` con los espectrogramas de Mel.\n        csv_path (str): Ruta relativa al CSV donde se almacenará o leerá el DataFrame resultante.\n\n    Returns:\n        pandas.DataFrame: DataFrame que contiene las rutas válidas a los espectrogramas de Mel generados para cada entrada de audio o video.\n\n    Notes:\n        - Si el archivo CSV especificado ya existe, se carga directamente.\n        - Si no existe, se genera cada espectrograma mediante `create_mel_spectrograms_ffmpeg`, y se eliminan las filas sin espectrograma válido.\n        - Se guarda un nuevo CSV con el resultado para evitar procesamiento redundante en futuras ejecuciones.\n        - Imprime por consola información sobre la forma inicial y final del DataFrame procesado.\n    \"\"\"\n    # Se define el path necesario para la carga del dataframe\n    main_folder = '/kaggle/working/'\n    file_path = os.path.join(main_folder, csv_path)\n    \n    if os.path.exists(file_path):\n        # Si el CSV con los paths a los Espectrogramas de Mel existe, se carga el dataframe\n        print(f\"Cargando CSV procesado desde {file_path}...\")\n        df_mel = pd.read_csv(file_path)\n    else:\n        # Se define el shape original antes de generar los Espectrogramas de Mel\n        original_shape = df_audio.shape\n\n        # Si el CSV con los paths a los Espectrogramas de Mel NO existe, se generan los Espectrogramas\n        print(f\"Generando espectrogramas...\")\n        df_mel = create_mel_spectrograms_ffmpeg(df_audio, output_folder = output_folder)\n\n        # Se eliminan las filas donde mel_path es None (o hay espetrograma por audio corrupto o vacío)\n        df_mel = df_mel[~df_mel['mel_path'].isna()]\n        df_mel = df_mel[df_mel['mel_path'].apply(lambda x: os.path.exists(x))]\n\n        # Se muestra la comparativa de shapes\n        print(f\"{csv_path} -> Shape inicial: {original_shape} | Shape final: {df_mel.shape}\")\n\n        # Se guarda el dataframe que contiene los paths a los Espectrogramas\n        df_mel.to_csv(csv_path, index = False)\n        \n    # Se devuelve el dataframe buscado\n    return df_mel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_in_chunks(df_audio, output_folder, final_csv_path, chunk_size = 5000):\n    \"\"\"\n    Función que genera espectrogramas de Mel en fragmentos del DataFrame para evitar sobrecarga de memoria, y guarda un CSV final con todos los resultados.\n\n    Args:\n        df_audio (pandas.DataFrame): DataFrame que contiene las rutas a los archivos de audio o video a procesar.\n        output_folder (str): Carpeta donde se guardarán los espectrogramas generados por cada fragmento.\n        final_csv_path (str): Ruta del archivo CSV donde se almacenará el DataFrame final con los espectrogramas generados.\n        chunk_size (int, optional): Número de filas por fragmento. Por defecto es 5000.\n\n    Returns:\n        pandas.DataFrame: DataFrame final que contiene todos los registros con sus correspondientes rutas a los espectrogramas de Mel.\n\n    Notes:\n        - El DataFrame se divide en fragmentos del tamaño definido por `chunk_size`.\n        - Cada fragmento se procesa mediante `create_mel_spectrograms_ffmpeg`, generando los espectrogramas en su propia subcarpeta.\n        - Se eliminan los registros con errores o sin espectrogramas válidos.\n        - Cada fragmento se guarda como un CSV temporal, que luego se concatena para formar el DataFrame final.\n        - El archivo CSV final se guarda en la ruta `final_csv_path` y contiene únicamente registros válidos.\n        - Esta función fue cerada específicamente para el Dataframe del dataset MOSEI de entrenamiento debido a su gran peso contra el Kernel.\n    \"\"\"\n    # Se crea la carpeta final si no existe\n    os.makedirs(output_folder, exist_ok = True)\n\n    # Se subdivide el dataframe en trozos para ir creando los espectrogramas\n    chunks = [df_audio[i:i+chunk_size] for i in range(0, df_audio.shape[0], chunk_size)]\n    all_chunk_paths = []\n\n    # Por cada trozo del dataframe\n    for idx, chunk in enumerate(chunks):\n        print(f\"\\nProcesando trozo {idx+1}/{len(chunks)}... ({chunk.shape[0]} filas)\")\n\n        # Se define el nombre del path del trozo actual\n        chunk_csv = f\"chunk_{idx}.csv\"\n        chunk_folder = os.path.join(output_folder, f\"chunk_{idx}\")\n\n        # Se crean los espectrogramas del trozo a estudiar\n        df_chunk = create_mel_spectrograms_ffmpeg(chunk, output_folder=chunk_folder)\n\n        # En caso de algún fallo, se eliminan dichos registros\n        df_chunk = df_chunk[~df_chunk['mel_path'].isna()]\n        df_chunk = df_chunk[df_chunk['mel_path'].apply(lambda x: os.path.exists(x))]\n\n        # Se guarda el trozo procesado para no perder el progreso\n        df_chunk.to_csv(chunk_csv, index = False)\n        all_chunk_paths.append(chunk_csv)\n\n    # Se concatenan todos los CSVs de cada trozo\n    dfs = [pd.read_csv(f) for f in all_chunk_paths]\n    final_df = pd.concat(dfs, ignore_index = True)\n\n    # Se guarda el CSV final\n    final_df.to_csv(final_csv_path, index = False)\n    print(f\"Dataset final guardado en {final_csv_path} ({final_df.shape[0]} filas)\")\n\n    # Se devuleve el dataframe final con sus paths de mel\n    return final_df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Funciones auxiliares para el Entrenamiento","metadata":{}},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"def random_swap(words, n = 2):\n    \"\"\"\n    Función que realiza intercambios aleatorios de posición entre palabras de una lista.\n\n    Args:\n        words (list of str): Lista de palabras sobre la que se aplicarán los intercambios.\n        n (int, optional): Número de intercambios aleatorios que se desea realizar. Por defecto es 2.\n\n    Returns:\n        list of str: Nueva lista de palabras con los elementos intercambiados aleatoriamente.\n\n    Notes:\n        - Los índices de las palabras a intercambiar se eligen de forma aleatoria e independiente.\n        - La función no modifica la lista original, sino que trabaja sobre una copia.\n    \"\"\"\n    # Se crea una copia de la lista de palabras del texto\n    new_words = words.copy()\n    \n    # Se intercambian aleatoriamente las palabras de posición\n    for _ in range(n):\n        idx1 = random.randint(0, len(new_words)-1)\n        idx2 = random.randint(0, len(new_words)-1)\n        new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n        \n    return new_words\n\ndef simple_text_augmentation(text, n_swaps = 2):\n    \"\"\"\n    Función que aplica una técnica simple de aumento de datos textuales mediante el intercambio aleatorio de palabras.\n\n    Args:\n        text (str): Cadena de texto sobre la que se desea aplicar el aumento de datos.\n        n_swaps (int, optional): Número de pares de palabras que se intercambiarán aleatoriamente. Por defecto es 2.\n\n    Returns:\n        str: Nueva cadena de texto resultante tras realizar los intercambios de palabras.\n\n    Notes:\n        - La función `random_swap` se encarga de realizar los intercambios aleatorios.\n    \"\"\"\n    # Se genera la lista de palabras del texto\n    words = text.split()\n\n    # Se intercambian las posiciones de ciertas palabras del texto aleatoriamente\n    new_words = random_swap(words, n = n_swaps)\n\n    # Se devuelve el nuevo texto para el data augmentation\n    return ' '.join(new_words)\n\ndef augment_dataframe_balanced(df):\n    \"\"\"\n    Función que equilibra un DataFrame aplicando aumento de datos textual para las clases minoritarias en la variable 'sentiment'.\n\n    Args:\n        df (pandas.DataFrame): DataFrame original.\n\n    Returns:\n        pandas.DataFrame: DataFrame balanceado, con las clases igualadas en número de muestras mediante aumento sintético de datos.\n\n    Notes:\n        - Se identifican las clases minoritarias en 'sentiment' y se calcula cuántas muestras faltan para igualar a la clase mayoritaria.\n        - Se realiza muestreo con reemplazo sobre las clases minoritarias y se aplica `simple_text_augmentation` para generar textos aumentados.\n    \"\"\"\n    # Se calcula el número de filas original del dataframe\n    original_len = len(df)\n\n    # Se define la lista de dataframes aumentados\n    augmented_dfs = []\n\n    # Se calcula el número de muestras por clase de sentimiento\n    class_counts = df['sentiment'].value_counts()\n\n    # Se extrae el máximo número de muestras que hay en una de las clases \n    max_count = class_counts.max()\n\n    # Por cada etiqueta y recuento de muestras de los sentimientos\n    for label, count in class_counts.items():\n        # Se extrae el sub-dataframe de dicho sentimiento\n        df_label = df[df['sentiment'] == label]\n        \n        # Se calcula cuantasmuestras son necesarias para igualar la clase minoritaria a la clase mayoritaria\n        n_needed = max_count - count\n\n        # Si se encuentra una clase minoritaria\n        if n_needed > 0:\n            # Se aplica el data augmentation por cambios posionales para obtener las muestras necesarias\n            sampled_df = df_label.sample(n = n_needed, replace = True, random_state = 42)\n            augmented_texts = [simple_text_augmentation(text) for text in sampled_df['text']]\n            augmented_df = sampled_df.copy()\n            augmented_df['text'] = augmented_texts\n            augmented_dfs.append(augmented_df)\n\n    # Se concatenan el dataframe original y lso sub-dataframes del data augmentation\n    df_augmented = pd.concat([df] + augmented_dfs, ignore_index = True)\n\n    # Se calcula el número de filas final del dataframe\n    final_len = len(df_augmented)\n\n    # Se calcula el número final de muestras por clase de sentimiento\n    final_class_counts = df_augmented['sentiment'].value_counts()\n\n    # Se muestra el balanceo de las muestras\n    print(\"\\n Resultado del balanceo:\")\n    print(f\"- Tamaño original del dataset: {original_len}\")\n    print(f\"- Tamaño después del augmentación: {final_len}\")\n    print(f\"- Número de muestras por clase antes del balanceo: {class_counts.sort_index()}\")\n    print(f\"- Número de muestras por clase después del balanceo: {final_class_counts.sort_index()}\")\n\n    # Se devuelve el dataframe balanceado y aumentado\n    return df_augmented","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Entrenamiento en texto","metadata":{}},{"cell_type":"code","source":"def prepare_text_feature_label_data(df, feature_cols):\n    \"\"\"\n    Función que extrae y organiza los datos de texto, labels y características numéricas desde un DataFrame para su uso en modelaje.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene las columnas 'text', 'sentiment' y las características especificadas.\n        feature_cols (list of str): Lista de nombres de columnas numéricas que se utilizarán como variables adicionales (features).\n\n    Returns:\n        tuple:\n            list of str: Lista de textos provenientes de la columna 'text'.\n            list of int: Lista de labels de sentimiento convertidas a enteros.\n            numpy.ndarray: Matriz de características numéricas extraídas de las columnas especificadas.\n    \"\"\"\n    # Se extrae la variable de texto a formato lista\n    text = df['text'].tolist()\n\n    # Se extraen las etiquetas del sentimiento a formato lista\n    labels = df['sentiment'].astype(int).tolist()\n\n    # Se definen las features\n    features = df[feature_cols].values\n    return text, labels, features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def measure_max_len(tokenizer, list_datasets, name_dataset, name_tokenizer, add_special_tokens = True):\n    \"\"\"\n    Función que determina la longitud máxima de tokens requerida para procesar un conjunto de textos, sin exceder el límite del tokenizador.\n\n    Args:\n        tokenizer (transformers.PreTrainedTokenizer): Tokenizador que se utilizará para codificar los textos.\n        list_datasets (list of list of str): Lista de listas de textos a evaluar.\n        name_dataset (str): Nombre del dataset.\n        name_tokenizer (str): Nombre del tokenizador.\n        add_special_tokens (bool, optional): Indica si se deben incluir tokens especiales (CLS, SEP, etc.) en la codificación. Por defecto es True.\n\n    Returns:\n        int: Longitud máxima de tokens a utilizar, ajustada al límite del modelo (`tokenizer.model_max_length`).\n\n    \"\"\"\n    # Se define la variable base\n    max_len = 0\n\n    # Entre todos los datasets, se buscam la longitud de texto máxima que el modelo procesará\n    for text in np.hstack(list_datasets):\n        input_ids = tokenizer.encode(text, add_special_tokens = add_special_tokens)\n        # Se actualiza la variable base\n        max_len = max(max_len, len(input_ids))\n    \n    print(f'Max token length for {name_dataset}: {max_len}')\n    print(f'Model {name_tokenizer} max token length: {tokenizer.model_max_length}')\n\n    # Se devuelve el valor mínimo entre el máximo del tokenizados y el máximo encontrado\n    return min(tokenizer.model_max_length, max_len)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history):\n    \"\"\"\n    Función que genera gráficos de la evolución del entrenamiento de un modelo, incluyendo Loss, F1-score y Accuracy por epoch.\n\n    Args:\n        history (dict): Diccionario que contiene las métricas por epoch. Debe incluir:\n            - 'train_loss', 'val_loss': Loss en entrenamiento y validación.\n            - 'train_f1', 'val_f1': F1-score en entrenamiento y validación.\n            - 'train_acc', 'val_acc': Accuracy en entrenamiento y validación.\n\n    Returns:\n        None: La función no devuelve valores; muestra directamente los gráficos en pantalla.\n\n    Notes:\n        - Se crean tres gráficos en una sola figura: uno para cada métrica.\n        - Cada gráfico compara el rendimiento en entrenamiento y validación a lo largo de las epochs.\n    \"\"\"\n    # Se definen el número de epochs totales\n    epochs = range(1, len(history['train_loss']) + 1)\n\n    plt.figure(figsize = (18,5))\n\n    # Se plotea la loss\n    plt.subplot(1, 3, 1)\n    plt.plot(epochs, history['train_loss'], label = 'Train Loss')\n    plt.plot(epochs, history['val_loss'], label = 'Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Loss over Epochs')\n    plt.legend()\n\n    # Se plotea el F1-score\n    plt.subplot(1, 3, 2)\n    plt.plot(epochs, history['train_f1'], label = 'Train F1')\n    plt.plot(epochs, history['val_f1'], label = 'Validation F1')\n    plt.xlabel('Epochs')\n    plt.ylabel('F1-score')\n    plt.title('F1-score over Epochs')\n    plt.legend()\n\n    # Se plotea el Accuracy\n    plt.subplot(1, 3, 3)\n    plt.plot(epochs, history['train_acc'], label = 'Train Accuracy')\n    plt.plot(epochs, history['val_acc'], label = 'Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy over Epochs')\n    plt.legend()\n\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def grid_search_hyperparameters(model_name, tokenizer, texts_train, features_train, labels_train, texts_dev, features_dev, labels_dev, max_len):\n    \"\"\"\n    Función que realiza un 'grid search' sobre ciertas combinaciones de hiperparámetros para entrenar un modelo Transformer.\n\n    Args:\n        model_name (str): Nombre del modelo Transformer a utilizar.\n        tokenizer (transformers.PreTrainedTokenizer): Tokenizador correspondiente al modelo.\n        texts_train (list of str): Textos del conjunto de entrenamiento.\n        features_train (numpy.ndarray): Variables numéricas del conjunto de entrenamiento.\n        labels_train (list or numpy.ndarray): Etiquetas del conjunto de entrenamiento.\n        texts_dev (list of str): Textos del conjunto de validación.\n        features_dev (numpy.ndarray): Variables numéricas del conjunto de validación.\n        labels_dev (list or numpy.ndarray): Etiquetas del conjunto de validación.\n        max_len (int): Longitud máxima de los textos tras tokenización.\n\n    Returns:\n        dict: Diccionario con la mejor combinación de hiperparámetros encontrada, incluyendo:\n            - 'batch_size'\n            - 'epochs'\n            - 'learning_rate'\n            - 'warm_up'\n            - 'best_f1'\n\n    Notes:\n        - Se evalúan combinaciones de `batch_size`, `epochs` y `learning_rate`.\n        - Para cada combinación, se entrena un modelo `HybridTransformerClassifier` y se evalúa el F1-score sobre el conjunto de validación.\n        - El entrenamiento se realiza utilizando `train_and_evaluate` y se almacena la mejor puntuación.\n        - El resultado final es la configuración con mayor F1-score.\n        - La búsqueda utiliza el dispositivo CUDA por defecto.\n    \"\"\"\n    # Se define el grid de hiperparámetros a probar\n    batch_sizes = [32, 64]\n    epochs_list = [8, 10]\n    learning_rates = [2e-5, 1e-5]\n\n    # Se define la lista para los resultados y el device\n    results = []\n    device = 'cuda'\n\n    # Por cada combianción\n    for batch_size, epochs, lr in product(batch_sizes, epochs_list, learning_rates):\n        print(f\"\\n Combinación a probar: batch = {batch_size}, epochs = {epochs}, LR = {lr}\")\n        \n        # Se crean los datasets y los dataloaders\n        train_dataset = SentimentDataset(texts_train, features_train, labels_train, tokenizer, max_len)\n        dev_dataset = SentimentDataset(texts_dev, features_dev, labels_dev, tokenizer, max_len)\n\n        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n        dev_loader = DataLoader(dev_dataset, batch_size = batch_size)\n\n        # Se define el modelo a estrenar\n        model = HybridTransformerClassifier(model_name, num_features = features_train.shape[1])\n\n        # Se entrena el modelo con la combinación escogida\n        trained_model, best_f1 = train_and_evaluate(\n            model,\n            train_loader,\n            dev_loader,\n            labels_train,\n            device,\n            epochs = epochs,\n            lr = lr,\n            warm_up = 0.1,\n            patience = 2,\n            verbose = False\n        )\n\n        # Se guardan los resultados del entrenamiento\n        results.append({\n            \"batch_size\": batch_size,\n            \"epochs\": epochs,\n            \"learning_rate\": lr,\n            \"warm_up\": 0.1,\n            \"best_f1\": best_f1\n        })\n\n    # Se ordenan los resultados de mejor a peor segun su F1-score\n    results = sorted(results, key=lambda x: x[\"best_f1\"], reverse=True)\n\n    # Se muestra la mejor combinación encontrada\n    print(\"\\nMejor combinaión:\")\n    print(f\"F1-score = {results[0]['best_f1']:.4f} | batch = {results[0]['batch_size']}, epochs = {results[0]['epochs']}, LR = {results[0]['learning_rate']}\")\n\n    # Se devuelven los mejores hiperparámetros\n    return results[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_feature_importance(features, labels, feature_names, top_n = 9, random_state = 42):\n    \"\"\"\n    Función que entrena un clasificador Random Forest para calcular la importancia de las variables numéricas \n    y genera un gráfico con las características más relevantes.\n\n    Args:\n        features (numpy.ndarray or pandas.DataFrame): Variables predictoras.\n        labels (array-like): Vector de etiquetas objetivo para el entrenamiento del modelo.\n        feature_names (list of str): Lista de nombres de las variables que corresponden a las columnas de `features`.\n        top_n (int, optional): Número de características más importantes a visualizar. Por defecto es 9.\n        random_state (int, optional): Semilla utilizada para reproducibilidad del Random Forest. Por defecto es 42.\n\n    Returns:\n        None: La función no retorna nada; muestra un gráfico de barras horizontales con las características más importantes.\n\n    Notes:\n        - Se utiliza un `RandomForestClassifier` con 100 árboles para calcular la importancia de cada variable.\n        - Las importancias se ordenan de mayor a menor.\n    \"\"\"\n    # Se asegura primero que features es un array\n    if isinstance(features, pd.DataFrame):\n        X = features.values\n    else:\n        X = features\n\n    # Se establecen las etiquetas como y\n    y = labels\n\n    # Se entrena el RandomForest para sacar la feature importance\n    rf = RandomForestClassifier(n_estimators = 100, \n                                random_state = random_state)\n    rf.fit(X, y)\n\n    # Se ebtienen las importancias y se ordenan de más a menos importantes\n    importances = rf.feature_importances_\n    indices = np.argsort(importances)[::-1]\n\n    # Se selecciona el top n features\n    top_indices = indices[:top_n]\n\n    # Se pletean las importanias\n    plt.figure(figsize = (10, 6))\n    plt.barh(range(top_n), importances[top_indices][::-1], align = 'center')\n    plt.yticks(range(top_n), [feature_names[i] for i in top_indices][::-1])\n    plt.xlabel('Feature Importance')\n    plt.title('Top Feature Importances')\n    plt.grid(True, linestyle='--', alpha = 0.7)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    \"\"\"\n    Dataset personalizado para tareas de clasificación de sentimientos que combina texto tokenizado y variables numéricas adicionales.\n\n    Args:\n        texts (list of str): Lista de textos que se desean tokenizar.\n        features (numpy.ndarray or list): Matriz de características numéricas asociadas a cada texto.\n        labels (list or numpy.ndarray): Etiquetas de clase para cada muestra.\n        tokenizer (transformers.PreTrainedTokenizer): Tokenizador utilizado para procesar los textos.\n        max_len (int, optional): Longitud máxima permitida para los textos tokenizados. Por defecto es 128.\n\n    Methods:\n        __len__(): Devuelve el número total de muestras del dataset.\n        __getitem__(idx): Devuelve un diccionario con los tensores necesarios para el modelo:\n            - 'input_ids': IDs de los tokens.\n            - 'attention_mask': Máscara de atención para el modelo.\n            - 'features': Variables numéricas adicionales.\n            - 'labels': Etiqueta de la muestra.\n    \"\"\"\n    def __init__(self, texts, features, labels, tokenizer, max_len = 128):\n        self.texts = texts\n        self.features = features\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n         # Se devuleve la cantidad total de muestras\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        # S extraen el texto, las features y la etiqueta del índice idx\n        text = self.texts[idx]\n        feature = self.features[idx]\n        label = self.labels[idx]\n        \n        # Se tokeniza el texto correspondiente\n        encoding = self.tokenizer(\n            text,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_len,\n            return_tensors = 'pt'\n        )\n\n        # Se devuleven los tensores resultantes\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'features': torch.tensor(feature, dtype = torch.float),\n            'labels': torch.tensor(label, dtype = torch.long)\n        }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HybridTransformerClassifier(nn.Module):\n    \"\"\"\n    Modelo híbrido que combina embeddings de un modelo Transformer preentrenado con variables numéricas adicionales para realizar clasificación.\n\n    Args:\n        model_name (str): Nombre del modelo Transformer.\n        num_features (int): Número de características numéricas adicionales.\n        num_classes (int, optional): Número de clases para la clasificación. Por defecto es 3.\n\n    Attributes:\n        transformer (AutoModel): Modelo Transformer preentrenado cargado.\n        feature_layer (nn.Linear): Capa lineal que transforma las variables numéricas a un espacio intermedio de dimensión 128.\n        norm (nn.LayerNorm): Capa de normalización sobre la concatenación del embedding y las features.\n        classifier (nn.Sequential): Red neuronal que realiza la clasificación final a partir del vector combinado.\n\n    Forward Args:\n        input_ids (torch.Tensor): Tensor de IDs de tokens con forma (batch_size, seq_len).\n        attention_mask (torch.Tensor): Máscara de atención con forma (batch_size, seq_len).\n        features (torch.Tensor): Tensor de variables numéricas adicionales con forma (batch_size, num_features).\n\n    Returns:\n        torch.Tensor: Logits de clase con forma (batch_size, num_classes).\n\n    Notes:\n        - Se utiliza `pooler_output` del Transformer como representación del texto. Si no está disponible, se usa el primer token de salida.\n        - Las variables numéricas se proyectan y concatenan con el embedding textual antes de pasar por el clasificador.\n    \"\"\"\n    def __init__(self, model_name: str, num_features: int, num_classes = 3):\n        super().__init__()\n\n        # Se define el transformer\n        self.transformer = AutoModel.from_pretrained(model_name)\n\n        # Se detecta automáticamente el tamaño del hidden del modelo\n        hidden_size = self.transformer.config.hidden_size\n\n        # Se define el procesador para las features\n        self.feature_layer = nn.Linear(num_features, 128)\n\n        # Se define una capa de normalización\n        self.norm = nn.LayerNorm(hidden_size + 128)\n\n        # Se define el clasificador\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size + 128, 128),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask, features):\n        # Se extrae el embedding del texto desde el pooler_output del transformer\n        outputs = self.transformer(input_ids = input_ids, attention_mask = attention_mask)\n\n        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n            pooled_output = outputs.pooler_output\n        else:\n            # Para XLNet se usará el primer token al no tener pooler_output\n            pooled_output = outputs.last_hidden_state[:, 0]\n\n        # Se procesan de las features \n        feature_out = self.feature_layer(features)\n\n        # Ae concatenan el texto y las features\n        combined = torch.cat((pooled_output, feature_out), dim = 1)\n\n        # Se clasifica\n        logits = self.classifier(combined)\n        return logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"\n    Clase que implementa la técnica de' Early Stopping' durante el entrenamiento de modelos para evitar sobreajuste.\n\n    Args:\n        patience (int, optional): Número de epochs consecutivas sin mejora del F1-score antes de detener el entrenamiento. Por defecto es 2.\n        verbose (bool, optional): Indica si se deben mostrar mensajes informativos cuando se guarda un nuevo mejor modelo. Por defecto es True.\n        save_path (str, optional): Ruta del archivo donde se guardará el mejor modelo. Por defecto es 'best_model.pt'.\n\n    Attributes:\n        best_score (float or None): Mejor valor de F1-score observado hasta el momento.\n        counter (int): Contador de epochs consecutivas sin mejora.\n        early_stop (bool): Indicador de si debe detenerse el entrenamiento.\n        save_path (str): Ruta al archivo donde se guarda el mejor modelo.\n\n    Methods:\n        __call__(score, model): Evalúa si el nuevo score mejora al anterior; guarda el modelo si mejora o aumenta el contador si no.\n        save_checkpoint(model): Guarda el estado del modelo en `save_path`.\n    \"\"\"\n    # Se define la clase EarlyStopping\n    def __init__(self, patience = 2, verbose = True, save_path = 'best_model.pt'):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.verbose = verbose\n        self.save_path = save_path\n\n    # Se define la llamada al earlyStopping cuando el entrenamiento se estanca\n    def __call__(self, score, model):\n        if self.best_score is None or score > self.best_score:\n            self.best_score = score\n            self.counter = 0\n            self.save_checkpoint(model)\n            if self.verbose:\n                print(f\"New best model saved with F1: {score:.4f}\")\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n                \n     # Se define el guardado del mejor modelo enoctrado            \n    def save_checkpoint(self, model):\n        torch.save(model.state_dict(), self.save_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def epoch_train(model, dataloader, optimizer, scheduler, loss_fn, device, verbose = True):\n    \"\"\"\n    Función que entrena un modelo durante una epoch completa usando un conjunto de datos proporcionado por un DataLoader.\n\n    Args:\n        model (torch.nn.Module): Modelo que se desea entrenar.\n        dataloader (torch.utils.data.DataLoader): DataLoader que proporciona los batches de entrenamiento.\n        optimizer (torch.optim.Optimizer): Optimizador para actualizar los pesos del modelo.\n        scheduler (torch.optim.lr_scheduler): Scheduler para ajustar la tasa de aprendizaje durante el entrenamiento.\n        loss_fn (callable): Función de pérdida a optimizar.\n        device (str): Dispositivo en el que se ejecutará el entrenamiento (es 'cuda').\n        verbose (bool, optional): Si es True, se muestra una barra de progreso. Por defecto es True.\n\n    Returns:\n        tuple:\n            float: Loss durante la epoch.\n            float: Aaccuracy en la epoch.\n            float: F1-score ponderado en la epoch.\n\n    Notes:\n        - Se pone el modelo en modo entrenamiento con `model.train()`.\n        - Los gradientes se reinician en cada batch con `optimizer.zero_grad()`.\n        - Se realiza forward pass, cálculo de pérdida, backward pass y actualización de pesos.\n        - Se acumulan predicciones y etiquetas reales para calcular métricas al final de la época.\n    \"\"\"\n    # Se pone el modelo en modo entreno\n    model.train()\n\n    # Se definen las variables base para la loss y las predicciones\n    total_loss = 0\n    all_preds, all_labels = [], []\n\n    # Por cada batch\n    for batch in tqdm(dataloader, disable = not verbose):\n        # Se extrae la información necesaria del dataloader para enviarla al device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        features = batch['features'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Se reinician los gradientes para evitar problemas de gradiente\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(input_ids = input_ids, \n                        attention_mask = attention_mask, \n                        features = features)\n        \n        # Se calcula la loss\n        loss = loss_fn(outputs, labels)\n\n        # Se realiza backpropagation y se actualizan los pesos y el scheduler\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # Se acumula la loss y extraen las predicciones\n        total_loss += loss.item()\n        preds = torch.argmax(outputs, dim = 1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().numpy())\n\n    # Se calculan las métricas globales: avg loss, ACC y F1-score\n    avg_loss = total_loss / len(dataloader)\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average = 'weighted')\n    return avg_loss, acc, f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, dataloader, loss_fn, device, verbose = True):\n    \"\"\"\n    Función que evalúa un modelo sobre un conjunto de validación sin actualizar los pesos, y calcula métricas de rendimiento.\n\n    Args:\n        model (torch.nn.Module): Modelo a evaluar.\n        dataloader (torch.utils.data.DataLoader): DataLoader que proporciona los batches de validación.\n        loss_fn (callable): Función de pérdida utilizada para calcular la Loss en cada batch.\n        device (str): Dispositivo en el que se ejecuta la evaluación (es 'cuda').\n        verbose (bool, optional): Si es True, puede activarse una barra de progreso externa. Por defecto es True.\n\n    Returns:\n        tuple:\n            float: Lloss durante la evaluación.\n            float: Accuracy total.\n            float: F1-score ponderado.\n            dict: Diccionario con las métricas detalladas del classification report (por clase y globales).\n\n    Notes:\n        - Se desactiva el cálculo de gradientes mediante `torch.no_grad()` para ahorrar memoria y acelerar la evaluación.\n        - Se pone el modelo en modo evaluación con `model.eval()`.\n    \"\"\"\n    # Se pone el modelo en modo evaluación\n    model.eval()\n\n    # Se definen las variables base para la loss y las predicciones\n    total_loss = 0\n    all_preds, all_labels = [], []\n\n    # Se le establece al modelo que no calcule o guarde los gradientes, así ahorrando memoria \n    # y aumentando la velocidad de las predicciones\n    with torch.no_grad():\n        # Por cada batch\n        for batch in dataloader:\n            # Se extrae la información necesaria del dataloader para enviarla al device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            features = batch['features'].to(device)\n            labels = batch['labels'].to(device)\n\n            # Forward pass sin backpropagation\n            outputs = model(input_ids = input_ids, \n                            attention_mask = attention_mask, \n                            features = features)\n            \n            # Se calcula la loss y se acumula\n            loss = loss_fn(outputs, labels)\n            total_loss += loss.item()\n\n            # Se extraen las predicciones\n            preds = torch.argmax(outputs, dim = 1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    # Se calculan las métricas globales: avg loss, ACC, F1-score y classification report\n    avg_loss = total_loss / len(dataloader)\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average = 'weighted', zero_division = 0)\n    report = classification_report(all_labels, all_preds, output_dict = True, zero_division = 0)\n    return avg_loss, acc, f1, report","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_evaluate(model, train_dataloader, dev_dataloader, labels_train, device, epochs = 5, lr = 2e-5, patience = 5, freeze_epochs = 2, warm_up =  0.1, verbose = True):\n    \"\"\"\n    Función que entrena un modelo durante varias épocas, evalúa su rendimiento en un conjunto de validación y aplica detención temprana (early stopping).\n\n    Args:\n        model (torch.nn.Module): Modelo a entrenar.\n        train_dataloader (DataLoader): DataLoader con los datos de entrenamiento.\n        dev_dataloader (DataLoader): DataLoader con los datos de validación.\n        labels_train (array): Etiquetas del conjunto de entrenamiento, usadas para calcular pesos de clase.\n        device (str): Dispositivo de cómputo (es 'cuda').\n        epochs (int, optional): Número total de epochs de entrenamiento. Por defecto es 5.\n        lr (float, optional): Tasa de aprendizaje inicial. Por defecto es 2e-5.\n        patience (int, optional): Número de epochs sin mejora antes de detener el entrenamiento anticipadamente. Por defecto es 5.\n        freeze_epochs (int, optional): Número de épocas iniciales durante las cuales las capas del Transformer permanecen congeladas. Por defecto es 2.\n        warm_up (float, optional): Porcentaje de pasos de entrenamiento usados para calentamiento del learning rate. Por defecto es 0.1.\n        verbose (bool, optional): Si es True, se muestra información de entrenamiento por consola. Por defecto es True.\n\n    Returns:\n        tuple:\n            torch.nn.Module: Modelo con los pesos del mejor estado encontrado según F1-score en validación.\n            float: Mejor F1-score alcanzado durante el mejor entrenamiento.\n\n    Notes:\n        - Se usa el optimizador AdamW y un scheduler con calentamiento y decaimiento tipo coseno.\n        - Se calculan pesos de clase para la función de pérdida (`CrossEntropyLoss`) de manera equilibrada.\n        - Las capas del Transformer pueden permanecer congeladas durante `freeze_epochs` iniciales.\n        - Se aplica early stopping basado en el F1-score de validación.\n    \"\"\"\n    # Se manda el modelo al device\n    model.to(device)\n\n    # Se defin el optimizador AdamW\n    optimizer = AdamW(model.parameters(), lr = lr)\n\n    # Se calculan los steps del dataloader\n    total_steps = len(train_dataloader) * epochs\n    warmup_steps = int(warm_up * total_steps)\n    \n    # Se define el scheduler para el LR\n    scheduler = get_cosine_schedule_with_warmup(optimizer,\n                                                num_warmup_steps = warmup_steps,\n                                                num_training_steps = total_steps)\n\n    # Se definen los pesos de las clases a predecir\n    labels = np.array(labels_train)\n    \n    # Se calculan los pesos de clas clases\n    class_weights = compute_class_weight(class_weight = 'balanced', \n                                         classes = np.unique(labels), \n                                         y = labels)\n    class_weights = torch.tensor(class_weights, dtype = torch.float)\n\n    # Se define la función de loss con pesos\n    loss_fn = nn.CrossEntropyLoss(weight = class_weights.to(device))\n\n    # Se define el EalyStopping\n    early_stopper = EarlyStopping(patience = patience)\n\n    # Se definen las variables base\n    best_f1 = 0\n    best_model_state = None\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'train_f1': [], 'val_f1': []}\n\n    # Se congelan las capas del transformer inicialmente\n    for param in model.transformer.parameters():\n        param.requires_grad = False\n\n    # Por cada epoch\n    for epoch in range(1, epochs + 1):\n        if verbose:\n            print(f\"\\n Epoch {epoch}\")\n        # Descongelar el transformer después de algunas épocas\n        if epoch == freeze_epochs + 1:\n            for param in model.transformer.parameters():\n                param.requires_grad = True\n                \n        # Se entrena el modelo\n        train_loss, train_acc, train_f1 = epoch_train(model, train_dataloader, optimizer, scheduler, loss_fn, device, verbose = verbose)\n        if verbose:\n            print(f\"Train Loss: {train_loss:.4f}, ACC: {train_acc:.4f}, F1-score: {train_f1:.4f}\")\n\n        # Se valida el modelo\n        val_loss, val_acc, val_f1, _ = evaluate(model, dev_dataloader, loss_fn, device, verbose = verbose)\n        if verbose:\n            print(f\"Val Loss: {val_loss:.4f}, ACC: {val_acc:.4f}, F1-score: {val_f1:.4f}\")\n\n        # Se actualiza el LR en función de la loss de validación\n        # scheduler.step(val_loss)\n\n        # Si ´se encuentra un mejor modelo, se guarda\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_model_state = model.state_dict()\n        \n        # Se añaden lso resultados a la historia del entrenamiento\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_acc'].append(train_acc)\n        history['val_acc'].append(val_acc)\n        history['train_f1'].append(train_f1)\n        history['val_f1'].append(val_f1)\n\n        # Se llama al Early stopper para saber si hay que parar el entrenamiento\n        early_stopper(val_f1, model)\n        if early_stopper.early_stop:\n            print(\"Early stopping triggered.\")\n            break\n\n    # Se guardan el estado del mejor modelo encontrado entre las epochs\n    model.load_state_dict(best_model_state)\n    \n    if verbose:\n        # Se plotea la historia del entrenamiento\n        plot_training_history(history)\n\n    # Se devuleve le modelo y la mejor F1-score\n    return model, best_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_model_competition(competition_dict, device = 'cuda', epochs = 5, lr = 2e-5, patience = 2, freeze_epochs = 1, warm_up = 0.1, verbose = False):\n    \"\"\"\n    Función que entrena y evalúa múltiples modelos en una competición para comparar su rendimiento sobre un conjunto de validación.\n\n    Args:\n        competition_dict (dict): Diccionario donde cada clave es el nombre del modelo y su valor es una tupla con:\n            (modelo, dataloader de entrenamiento, dataloader de validación, etiquetas de entrenamiento).\n        device (str, optional): Dispositivo sobre el cual se ejecutará el entrenamiento. Por defecto es 'cuda'.\n        epochs (int, optional): Número de epochs de entrenamiento. Por defecto es 5.\n        lr (float, optional): Tasa de aprendizaje inicial. Por defecto es 2e-5.\n        patience (int, optional): Número de epochs sin mejora antes de aplicar early stopping. Por defecto es 2.\n        freeze_epochs (int, optional): Número de epochs iniciales con el modelo Transformer congelado. Por defecto es 1.\n        warm_up (float, optional): Proporción de pasos para el calentamiento del learning rate. Por defecto es 0.1.\n        verbose (bool, optional): Si es True, se imprime información detallada durante el entrenamiento. Por defecto es False.\n\n    Returns:\n        tuple:\n            str: Nombre del modelo con mejor F1-score macro.\n            torch.nn.Module: Modelo entrenado correspondiente al mejor rendimiento.\n            dict: Diccionario con las métricas del mejor modelo, incluyendo:\n                - 'accuracy': Accuracy total.\n                - 'f1_macro': F1-score macro.\n                - 'f1_weighted': F1-score ponderado por clase.\n                - 'aucs': Accuracy por clase si es posible.\n                - 'model': Modelo entrenado.\n\n    Notes:\n        - Cada modelo se entrena mediante la función `train_and_evaluate`.\n        - Se evalúa el rendimiento sobre el conjunto de validación usando `predict`.\n        - Se calcula el AUC por clase cuando sea posible; si no, se asigna `NaN`.\n        - El modelo con mayor F1-score macro es seleccionado como el mejor.\n    \"\"\"\n    # Se define el diccionario de los resultados\n    results = {}\n\n    # Por cada candidato en la competición\n    for model_name, (model, train_dataloader, dev_dataloader, labels_train) in competition_dict.items():\n        print(f\"Entrenando el modelo {model_name}\")\n\n        # Se manda el modelo a entrenar\n        trained_model, _ = train_and_evaluate(model, \n                                              train_dataloader, \n                                              dev_dataloader, \n                                              labels_train = labels_train, \n                                              device = device,\n                                              epochs = epochs,\n                                              lr = lr,\n                                              patience = patience,\n                                              freeze_epochs = freeze_epochs,\n                                              warm_up = warm_up,\n                                              verbose = verbose)\n\n        # Se predice usando el modelo entrenamos\n        preds_dev, probs_dev = predict(trained_model, dev_dataloader, device)\n        true_labels_dev = [batch['labels'].cpu().numpy() for batch in dev_dataloader]\n        true_labels_dev = np.concatenate(true_labels_dev)\n\n        # Se calculan las métricas pertinentes al estudio: Accuracy, F1-macro y F1-weighted\n        acc = accuracy_score(true_labels_dev, preds_dev)\n        f1_macro = f1_score(true_labels_dev, preds_dev, average = 'macro')\n        f1_weighted = f1_score(true_labels_dev, preds_dev, average = 'weighted')\n\n        # Se calcula el AUC\n        aucs = {}\n        for i in range(probs_dev.shape[1]):\n            try:\n                aucs[i] = roc_auc_score((true_labels_dev == i).astype(int), probs_dev[:, i])\n            except:\n                aucs[i] = np.nan\n\n        # Se guardan los resultados del modelo entrenado con sus métricas\n        results[model_name] = {\n            'accuracy': acc,\n            'f1_macro': f1_macro,\n            'f1_weighted': f1_weighted,\n            'aucs': aucs,\n            'model': trained_model\n        }\n\n        print(f\"{model_name} - ACC: {acc:.4f} - F1-macro: {f1_macro:.4f}\\n\")\n\n    # Se escoge el mejor modelo basándose en F1-macro\n    best_model_name = max(results, key = lambda x: results[x]['f1_macro'])\n    best_model = results[best_model_name]['model']\n\n    print(f\"\\nMejor modelo: {best_model_name} con F1-macro: {results[best_model_name]['f1_macro']:.4f}\")\n\n    # Se devuelve el mejor modelo y sus resultados\n    return best_model_name, best_model, results[best_model_name]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_predictions_to_csv(original_csv_path, output_csv_path, predictions):\n    \"\"\"\n    Función que añade las predicciones del modelo como columnas a un CSV existente y guarda el resultado en una nueva ruta.\n\n    Args:\n        original_csv_path (str): Ruta al archivo CSV original.\n        output_csv_path (str): Ruta donde se guardará el nuevo archivo CSV con las predicciones añadidas.\n        predictions (numpy.ndarray): Matriz de predicciones con forma (n_samples, 3), correspondiente a las clases [negativo, neutral, positivo].\n\n    Returns:\n        None: La función guarda el archivo modificado, no devuelve ningún valor.\n    \"\"\"\n    # Se carga el CSV original\n    df = pd.read_csv(original_csv_path)\n\n    # Se añaden las predicciones como nuevas columnas\n    df['pred_negative'] = predictions[:, 0]\n    df['pred_neutral'] = predictions[:, 1]\n    df['pred_positive'] = predictions[:, 2]\n\n    # Se guarda el nuevo CSV\n    df.to_csv(output_csv_path, index = False)\n\ndef save_best_model(best_model_path, best_model):\n    \"\"\"\n    Función que guarda en disco el estado de un modelo entrenado.\n\n    Args:\n        best_model_path (str): Ruta donde se desea guardar el modelo.\n        best_model (torch.nn.Module): Modelo ya entrenado.\n\n    Returns:\n        None: El modelo se guarda como archivo binario en la ruta especificada.\n    \"\"\"\n    # Se guarda el modelo entrenado\n    torch.save(best_model.state_dict(), best_model_path)\n\ndef save_preds_and_best_model(original_csv_paths, output_csv_paths, best_model_path, predictions, best_model):\n    \"\"\"\n    Función que guarda las predicciones en múltiples archivos CSV y almacena el mejor modelo entrenado.\n\n    Args:\n        original_csv_paths (list of str): Lista de rutas a los CSV originales.\n        output_csv_paths (list of str): Lista de rutas donde se guardarán los CSV con las predicciones.\n        best_model_path (str): Ruta donde se guardará el mejor modelo entrenado.\n        predictions (list of numpy.ndarray): Lista de arrays de predicciones, uno por CSV.\n        best_model (torch.nn.Module): Modelo entrenado a guardar.\n    \"\"\"\n    # Se guardan las predicciones del mejor modelo\n    for original_path, output_path, prediction in zip(original_csv_paths, output_csv_paths, predictions):\n        add_predictions_to_csv(original_path, output_path, prediction)\n\n    # Se guarda el modelo entrenado\n    save_best_model(best_model_path, best_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Entrenamiento en audio","metadata":{}},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    \"\"\"\n    Dataset personalizado para tareas de reconocimiento de emociones a partir de espectrogramas de Mel, con soporte para etiquetas únicas o múltiples.\n\n    Args:\n        df (pandas.DataFrame): DataFrame que contiene las rutas a los espectrogramas y las etiquetas asociadas.\n        extra_features_cols (list of str, optional): Lista de columnas con características adicionales numéricas. Si no se especifica, se omiten. Por defecto es None.\n        label_cols (str or list of str, optional): Nombre de la columna (para clasificación simple con MELD) o lista de columnas (para clasificación multietiqueta con MOSEI). Por defecto es 'Emotion'.\n        multi_label (bool, optional): Indica si la tarea es multietiqueta (True para MOSEI) o clasificación simple (False para MELD). Por defecto es False.\n\n    Methods:\n        __len__(): Devuelve el número de muestras en el dataset.\n        __getitem__(idx): Devuelve una tupla (mel, extra_features, label) para el índice `idx`.\n\n    Returns:\n        tuple:\n            torch.Tensor: Tensor del espectrograma de Mel con forma (1, H, W).\n            torch.Tensor: Vector de características adicionales o tensor de ceros si no hay.\n            torch.Tensor: Etiqueta de clase (entero para MELD) o vector multietiqueta (float para MOSEI).\n\n    Notes:\n        - El espectrograma se carga desde la ruta contenida en la columna 'mel_path'.\n        - Si `multi_label` es True, se asume que las columnas de etiqueta contienen valores en varias de ellas.\n        - Si `multi_label` es False, la etiqueta es un entero representando una única clase emocional.\n    \"\"\"\n    def __init__(self, df, extra_features_cols = None, label_cols = 'Emotion', multi_label = False):\n        self.df = df\n        self.extra_features_cols = extra_features_cols if extra_features_cols is not None else []\n        self.label_cols = label_cols\n        self.multi_label = multi_label\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Se encuentra la fila a estudiar\n        row = self.df.iloc[idx]\n        \n        # Se carga el Espectrograma de Mel\n        mel_path = row['mel_path']\n        mel = np.load(mel_path)\n        mel = torch.tensor(mel, dtype = torch.float).unsqueeze(0)\n\n        # Se cargan las features\n        if self.extra_features_cols:\n            extra_features = torch.tensor(row[self.extra_features_cols].astype(np.float32).values, dtype = torch.float)\n        else:\n            extra_features = torch.zeros(1)\n\n        # Se carga la/s etiqueta/s\n        if self.multi_label:\n            # Si es MOSEI (7 columnas que van a un vector de emociones)\n            label = torch.tensor(row[self.label_cols].astype(np.float32).values, dtype = torch.float)\n        else:\n            # Si es MELD (1 única columna llamada Emotion)\n            label = torch.tensor(np.int64(row[self.label_cols]), dtype = torch.long)\n\n        return mel, extra_features, label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EmotionModel(nn.Module):\n    \"\"\"\n    Modelo híbrido para reconocimiento de emociones a partir de espectrogramas de Mel, que combina una red CNN con atención y características numéricas adicionales.\n\n    Args:\n        backbone_name (str): Nombre del backbone CNN a utilizar. Actualmente soporta 'vgg16' y 'efficientnet_b0'.\n        num_extra_features (int, optional): Número de características adicionales extras. Por defecto es 3.\n        num_classes (int, optional): Número de clases emocionales de salida. Por defecto es 7.\n\n    Attributes:\n        backbone_before_attention (nn.Sequential): Parte inicial del backbone antes de aplicar el primer módulo de atención.\n        backbone_after_attention (nn.Sequential): Parte restante del backbone tras aplicar la atención intermedia.\n        attention_0 (nn.Sequential): Primer módulo de atención para features intermedias.\n        attention_1 (nn.Sequential): Segundo módulo de atención para features más profundas.\n        classifier (nn.Sequential): Clasificador final que combina las features del espectrograma y las extra_features.\n\n    Forward Args:\n        mel (torch.Tensor): Espectrograma de Mel con forma (batch_size, 1, H, W).\n        extra_features (torch.Tensor): Tensor con variables numéricas adicionales por muestra, con forma (batch_size, num_extra_features).\n\n    Returns:\n        torch.Tensor: Logits de salida con forma (batch_size, num_classes).\n\n    Notes:\n        - El modelo aplica dos módulos de atención: uno a nivel intermedio y otro profundo, ambos aprendidos con convoluciones 1x1.\n        - Las features finales se concatenan con `extra_features` antes de pasar por el clasificador.\n        - Si se proporciona un backbone no soportado, se lanza un ValueError.\n    \"\"\"\n    def __init__(self, backbone_name: str, num_extra_features: int = 3, num_classes: int = 7):\n        super().__init__()\n        # Se define el nombre del modelo escogido\n        self.backbone_name = backbone_name\n\n        if self.backbone_name == \"vgg16\":\n            # Se carga el modelo pre-entrenado\n            vgg = models.vgg16(weights = VGG16_Weights.IMAGENET1K_V1)\n            \n            # Se cambia la primera capa de convolución de 3 canales a un único canal\n            vgg.features[0] = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n\n            # Se divide el entrenamiento entre\n            # A) la parte antes de la cuarta convolución\n            self.backbone_before_attention = nn.Sequential(*vgg.features[:17])\n            # B) la parte a partir de la cuarta convolución\n            self.backbone_after_attention = nn.Sequential(*vgg.features[17:])\n\n            # Se definen los canales resultantes local y global\n            self.out_channels_local = 256\n            self.out_channels_global = 512\n\n\n        elif self.backbone_name == \"efficientnet_b0\":\n            # Se carga el modelo pre-entrenado\n            effnet = models.efficientnet_b0(weights = 'IMAGENET1K_V1')\n\n            # Del primer Sequential, se cambia la primera capa, que es de convolución, de 3 canales a un único canal\n            effnet.features[0][0] = nn.Conv2d(1, 32, kernel_size = 3, stride = 2, padding = 1, bias = False)\n\n            # Se divide el entrenamiento entre\n            # A) la parte antes de la cuarta convolución\n            self.backbone_before_attention = nn.Sequential(*effnet.features[:3])\n            # B) la parte a partir de la cuarta convolución\n            self.backbone_after_attention = nn.Sequential(*effnet.features[3:])\n\n            # Se definen los canales resultantes local y global\n            self.out_channels_local = 24\n            self.out_channels_global = 1280\n\n        else:\n            raise ValueError(f\"Backbone {backbone_name} no soportado aún.\")\n\n        # Se definen los módulos de atención\n        self.attention_0 = nn.Sequential(nn.Conv2d(self.out_channels_local, self.out_channels_local, kernel_size = 1), nn.Sigmoid())\n        self.attention_1 = nn.Sequential(nn.Conv2d(self.out_channels_global, self.out_channels_global, kernel_size = 1),nn.Sigmoid())\n\n        # Se definen las features totales y el clasificador\n        total_features = self.out_channels_local + self.out_channels_global + num_extra_features\n        self.classifier = nn.Sequential(\n            nn.Linear(total_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, mel, extra_features):\n        # Se ejecuta hasta la tercera convolución\n        x = self.backbone_before_attention(mel)\n\n        # Se ejecuta el módulo de atención 0\n        attn0 = self.attention_0(x)\n\n        # Se extraen las features locales del módulo de atención 0\n        local_feat0 = torch.mean(x * attn0, dim = [2,3])\n\n        # Se ejecuta la cuarta convolución\n        x = self.backbone_after_attention(x)\n\n        # Se ejecuta el módulo de atención 1\n        attn1 = self.attention_1(x)\n        \n        # Se extraen las features locales del módulo de atención 1\n        local_feat1 = torch.mean(x * attn1, dim = [2,3])\n\n        # Se concatenan:\n        #    - Las features locales del módulo de atención 0\n        #    - Las features locales del módulo de atención 1\n        #    - Las features externas del dataset\n        final_feat = torch.cat([local_feat0, local_feat1, extra_features], dim = 1)\n\n        # Se clasifica la emoción\n        logits = self.classifier(final_feat)\n        return logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def epoch_train_audio(model, dataloader, optimizer, scheduler, loss_fn, device, multilabel = False, verbose = True):\n    \"\"\"\n    Función que entrena un modelo con espectrogramas de Mel durante una epoch, manejando tareas de clasificación simple (MELD) o multietiqueta (MOSEI).\n\n    Args:\n        model (torch.nn.Module): Modelo a entrenar.\n        dataloader (DataLoader): DataLoader que proporciona los batches de entrenamiento (mel, extra_features, labels).\n        optimizer (torch.optim.Optimizer): Optimizador utilizado para actualizar los pesos del modelo.\n        scheduler (torch.optim.lr_scheduler): Scheduler para ajustar la tasa de aprendizaje.\n        loss_fn (callable): Función de pérdida a minimizar.\n        device (str): Dispositivo (es 'cuda') donde se ejecuta el entrenamiento.\n        multilabel (bool, optional): Si es True, se asume una tarea multietiqueta (MOSEI). Si es False, se asume clasificación única (MELD). Por defecto es False.\n        verbose (bool, optional): Si es True, se imprime información sobre la pérdida y métricas al finalizar la época. Por defecto es True.\n\n    Returns:\n        tuple:\n            float: Loss de la epoch.\n            float or None: Accuracy (solo si MELD).\n            float: F1-score macro, ajustado a cada tipo de tarea.\n\n    Notes:\n        - Para tareas multietiqueta, se utiliza `sigmoid` y un umbral de 0.5 para predicción.\n        - Para tareas monoetiqueta, se utiliza `softmax` y `argmax` para obtener la clase más probable.\n        - Se utiliza F1-score como métrica principal en ambos casos.\n        - Los tensores se acumulan a lo largo de la época para calcular métricas agregadas.\n        - El scheduler se actualiza al final de la época.\n    \"\"\"\n    # Se pone el modelo en modo entreno\n    model.train()\n\n    # Se definen las variables base\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_probs = []\n    all_labels = []\n\n    # Por cada espectrograma\n    for mel, extra_features, labels in dataloader:\n        # Se extrae la información necesaria del dataloader para enviarla al device\n        mel = mel.to(device)\n        extra_features = extra_features.to(device)\n        labels = labels.to(device)\n\n        # Se reinician los gradientes para evitar problemas de gradiente\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(mel, extra_features)\n\n        # Se calcula la loss en función del dataset a estudiar\n        #    - multilabel = True  --> MOSEI\n        #    - multilabel = False --> MELD\n        if multilabel:\n            loss = loss_fn(outputs, labels.float())\n        else:\n            loss = loss_fn(outputs, labels)\n            \n        # Se realiza backpropagation y se actualizan los pesos\n        loss.backward()\n        optimizer.step()\n\n        # Se acumula la loss\n        total_loss += loss.item()\n\n        # Se extraen las predicciones\n        if multilabel:\n            probs = torch.sigmoid(outputs).detach().cpu()   \n            preds = torch.sigmoid(outputs).detach().cpu()\n            pred_labels = (preds > 0.5).int()\n        else:\n            probs = torch.softmax(outputs, dim = 1).cpu()\n            preds = torch.argmax(outputs, dim = 1).detach().cpu()\n            pred_labels = preds\n\n        labels = labels.cpu()\n        all_preds.append(pred_labels)\n        all_probs.append(probs)\n        all_labels.append(labels)\n\n        # En el caso de MELD, se ajustan las etiquetas\n        if not multilabel:\n            correct += (pred_labels == labels).sum().item()\n            total += labels.size(0)\n\n    # Se actualiza el scheduler\n    scheduler.step()\n\n    # Se agrupan todas las predicciones, probabilidades y etiquetas\n    all_preds = torch.cat(all_preds)\n    all_probs = torch.cat(all_probs)\n    all_labels = torch.cat(all_labels)\n\n    all_probs_np = all_probs.detach().cpu().numpy()\n    all_labels_np = all_labels.detach().cpu().numpy()\n\n    # Se calcula la métrica global\n    #    - AUC-ROC si es MOSEI\n    #    - F1-score si es MELD\n    if multilabel:\n        all_labels_np = (all_labels_np > 0.5).astype(int)\n        all_probs_np = (all_probs_np > 0.5).astype(int)\n        score = f1_score(all_labels_np, all_probs_np , average = 'macro', zero_division = 0)\n        acc = None\n    else:\n        score = f1_score(all_labels.numpy(), all_preds.numpy(), average = \"macro\")\n        acc = correct / total\n\n    # Se calcula la loss global\n    avg_loss = total_loss / len(dataloader)\n\n    # Se muestran los resultados\n    if verbose:\n        print(f\"Train Loss: {avg_loss:.4f}, ACC: {acc:.4f} F1-score: {score:.4f}\" if acc is not None else f\"Train Loss: {avg_loss:.4f}, f1-score: {score:.4f}\")\n    return avg_loss, acc, score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_audio(model, dataloader, loss_fn, device, multilabel = False, verbose = True):\n    \"\"\"\n    Función que evalúa un modelo sobre espectrogramas de Mel sin actualizar los pesos, para tareas monoetiqueta (MELD) o multietiqueta (MOSEI).\n\n    Args:\n        model (torch.nn.Module): Modelo a evaluar.\n        dataloader (DataLoader): DataLoader que proporciona los batches de validación o prueba (mel, extra_features, labels).\n        loss_fn (callable): Función de pérdida a utilizar.\n        device (str): Dispositivo (es 'cuda') sobre el cual se ejecutará la evaluación.\n        multilabel (bool, optional): Indica si se trata de una tarea multietiqueta (True para MOSEI) o monoetiqueta (False para MELD). Por defecto es False.\n        verbose (bool, optional): Si es True, se imprime por consola la pérdida y métricas al final. Por defecto es True.\n\n    Returns:\n        tuple:\n            float: Loss durante la evaluación.\n            float or None: Accuracy, solo aplicable en tareas monoetiqueta de MELD.\n            float: F1-score macro para ambas tareas.\n\n    Notes:\n        - Para tareas multietiqueta (MOSEI), se utiliza `sigmoid` y umbral de 0.5 para clasificar cada emoción.\n        - Para tareas monoetiqueta (MELD), se utiliza `softmax` y `argmax` para predecir la clase.\n        - No se calculan gradientes (`torch.no_grad()`) para acelerar la inferencia y reducir uso de memoria.\n        - Se calcula el F1-score macro en ambos casos, y Accuracy en tareas monoetiqueta (MELD).\n    \"\"\"\n    # Se manda el modelo a modo evaluación\n    model.eval()\n\n    # Se definen todas las variables base\n    total_loss = 0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_probs = []\n    all_labels = []\n\n    # Se le establece al modelo que no calcule o guarde los gradientes, así ahorrando memoria \n    # y aumentando la velocidad de las predicciones\n    with torch.no_grad():\n        # Por cada espectrograma\n        for mel, extra_features, labels in dataloader:\n            # Se extrae la información necesaria del dataloader para enviarla al device\n            mel = mel.to(device)\n            extra_features = extra_features.to(device)\n            labels = labels.to(device)\n\n            # Forward pass sin backpropagation\n            outputs = model(mel, extra_features)\n\n            # Se calcula la loss en función del dataset a estudiar\n            #    - multilabel = True  --> MOSEI\n            #    - multilabel = False --> MELD\n            if multilabel:\n                loss = loss_fn(outputs, labels.float())\n            else:\n                loss = loss_fn(outputs, labels)\n\n            # Se acumula la loss\n            total_loss += loss.item()\n\n            # Se extraen las predicciones\n            if multilabel:\n                probs = torch.sigmoid(outputs).detach().cpu()\n                preds = torch.sigmoid(outputs).cpu()\n                pred_labels = (preds > 0.5).int()\n            else:\n                probs = torch.softmax(outputs, dim = 1).cpu()\n                preds = torch.argmax(outputs, dim = 1).cpu()\n                pred_labels = preds\n\n            labels = labels.cpu()\n            all_preds.append(pred_labels)\n            all_probs.append(probs)\n            all_labels.append(labels)\n\n            # En el caso de MELD, se ajustan las etiquetas\n            if not multilabel:\n                correct += (pred_labels == labels).sum().item()\n                total += labels.size(0)\n\n    # Se agrupan todas las predicciones y etiquetas\n    all_preds = torch.cat(all_preds)\n    all_probs = torch.cat(all_probs)\n    all_labels = torch.cat(all_labels)\n\n    all_probs_np = all_probs.detach().cpu().numpy()\n    all_labels_np = all_labels.detach().cpu().numpy()\n\n    # Se calcula la métrica global\n    #    - AUC-ROC si es MOSEI\n    #    - F1-score si es MELD\n    if multilabel:\n        all_labels_np = (all_labels_np > 0.5).astype(int)\n        all_probs_np = (all_probs_np > 0.5).astype(int)\n        score = f1_score(all_labels_np, all_probs_np, average = 'macro', zero_division = 0)\n        acc = None\n    else:\n        score = f1_score(all_labels.numpy(), all_preds.numpy(), average = \"macro\")\n        acc = correct / total\n        \n    # Se calcula la loss global\n    avg_loss = total_loss / len(dataloader)\n\n    # Se muestran los resultados\n    if verbose:\n        print(f\"Val Loss: {avg_loss:.4f}, ACC: {acc:.4f} F1-score: {score:.4f}\" if acc is not None else f\"Val Loss: {avg_loss:.4f}, AUC: {score:.4f}\")\n    return avg_loss, acc, score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_evaluate_audio(model, train_loader, dev_loader, num_epochs = 10, lr = 1e-4, patience = 2, multilabel = False, verbose = True):\n    \"\"\"\n    Función que entrena y evalúa un modelo basado en espectrogramas de Mel para tareas de clasificación monoetiqueta (MELD) o multietiqueta (MOSEI),\n    aplicando early stopping y guardando el mejor modelo.\n\n    Args:\n        model (torch.nn.Module): Modelo a entrenar y evaluar.\n        train_loader (DataLoader): DataLoader con los datos de entrenamiento.\n        dev_loader (DataLoader): DataLoader con los datos de validación.\n        num_epochs (int, optional): Número máximo de epochs. Por defecto es 10.\n        lr (float, optional): Tasa de aprendizaje inicial para el optimizador AdamW. Por defecto es 1e-4.\n        patience (int, optional): Número de epochs sin mejora antes de detener el entrenamiento anticipadamente. Por defecto es 2.\n        multilabel (bool, optional): Si es True, se asume una tarea multietiqueta (MOSEI). Si es False, se asume monoetiqueta (MELD). Por defecto es False.\n        verbose (bool, optional): Si es True, se imprimen métricas y curva de entrenamiento. Por defecto es True.\n\n    Returns:\n        tuple:\n            torch.nn.Module: Modelo entrenado con los mejores pesos encontrados durante el entrenamiento.\n            float: Mejor F1-score macro obtenido en validación.\n\n    Notes:\n        - Se usa `CrossEntropyLoss` para clasificación simple (MELD) y `BCEWithLogitsLoss` para clasificación multietiqueta (MOSEI).\n        - Se aplica un scheduler `StepLR` para reducir el LR cada 5 epochs (factor 0.5).\n        - Se almacena un historial completo de métricas y se puede visualizar mediante `plot_training_history` si verbose es True.\n        - Se activa detención temprana si el F1-score en validación no mejora durante `patience` epochs consecutivas.\n    \"\"\"\n    # Se manda el modelo al device\n    device = 'cuda'\n    model = model.to(device)\n\n    # Se define el optimizador AdamW\n    optimizer = AdamW(model.parameters(), lr = lr, weight_decay = 1e-4)\n\n    # Se define el scheduler para el LR\n    scheduler = StepLR(optimizer, step_size = 5, gamma = 0.5)\n\n    # Se define la función de loss en función del dataset\n    #    - multilabel = True  --> MOSEI\n    #    - multilabel = False --> MELD\n    if multilabel:\n        loss_fn = nn.BCEWithLogitsLoss()\n    else:\n        loss_fn = nn.CrossEntropyLoss()\n        \n    # Se define la historia\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'train_f1': [], 'val_f1': []}\n\n    # Se define el EalyStopping\n    early_stopping = EarlyStopping(patience = patience, verbose = True)\n\n    # Se definen las variables base\n    best_f1 = 0\n    best_model_state = None\n    \n    # Por cada epoch\n    for epoch in range(num_epochs):\n        if verbose:\n            print(f\"\\n Epoch {epoch}\")\n\n        # Se entrena el modelo\n        train_loss, train_acc, train_score = epoch_train_audio(model, train_loader, optimizer, scheduler, loss_fn, device, multilabel, verbose)\n\n        # Se valida el modelo\n        val_loss, val_acc, val_score = evaluate_audio(model, dev_loader, loss_fn, device, multilabel, verbose)\n\n         # Si se encuentra un mejor modelo, se guarda\n        if val_score > best_f1:\n            best_f1 = val_score\n            best_model_state = model.state_dict()\n            \n        # Se añaden lso resultados a la historia del entrenamiento\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_acc'].append(train_acc)\n        history['val_acc'].append(val_acc)\n        history['train_f1'].append(train_score)\n        history['val_f1'].append(val_score)\n\n\n        # Se llama al Early stopper para saber si hay que parar el entrenamiento\n        early_stopping(val_score, model)\n        if early_stopping.early_stop:\n            print(\"Early stopping triggered.\")\n            break\n\n    # Se guarda el estado del mejor modelo encontrado entre las epochs\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n    \n    if verbose:\n        # Se plotea la historia del entrenamiento\n        plot_training_history(history)\n\n    # Se devuleve le modelo\n    return model, best_f1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_audio_model_competition(competition_dict, device = 'cuda', epochs = 5, lr = 1e-4, patience = 2, multilabel = False, verbose = False):\n    \"\"\"\n    Función que entrena y compara múltiples modelos de audio basados en espectrogramas de Mel para seleccionar el que obtiene el mejor F1-score en validación.\n\n    Args:\n        competition_dict (dict): Diccionario con la forma \n            {'model_name': (modelo, dataloader_entrenamiento, dataloader_validación)}.\n        device (str, optional): Dispositivo sobre el cual se ejecutará el entrenamiento. Por defecto es 'cuda'.\n        epochs (int, optional): Número de epochs de entrenamiento. Por defecto es 5.\n        lr (float, optional): Tasa de aprendizaje para el optimizador AdamW. Por defecto es 1e-4.\n        patience (int, optional): Número de epochs sin mejora antes de aplicar early stopping. Por defecto es 2.\n        multilabel (bool, optional): Si es True, se asume una tarea multietiqueta (MOSEI); si es False, una tarea monoetiqueta (MELD). Por defecto es False.\n        verbose (bool, optional): Si es True, se muestra información detallada del entrenamiento. Por defecto es False.\n\n    Returns:\n        tuple:\n            str: Nombre del modelo con mejor rendimiento.\n            torch.nn.Module: Modelo entrenado correspondiente.\n            dict: Diccionario con las métricas del mejor modelo, incluyendo:\n                - 'f1_score': F1-score obtenido.\n                - 'model': Modelo entrenado.\n\n    Notes:\n        - La evaluación se realiza usando `train_and_evaluate_audio` y `predict_audio`.\n        - Se guarda el mejor modelo con base en el F1-score macro sobre el conjunto de validación.\n        - Para tareas multietiqueta (MOSEI) se utiliza `BCEWithLogitsLoss`; para monoetiqueta (MELD), `CrossEntropyLoss`.\n    \"\"\"\n    # Se define el disccionario para los esultados de la competición\n    results = {}\n\n    # Por cada modelo que compite\n    for model_name, (model, train_dataloader, dev_dataloader) in competition_dict.items():\n        print(f\"Entrenando modelo {model_name}...\")\n\n        # Se define la función de loss en función del dataset\n        #    - multilabel = True  --> MOSEI\n        #    - multilabel = False --> MELD\n        if multilabel:\n            loss_fn = nn.BCEWithLogitsLoss()\n        else:\n            loss_fn = nn.CrossEntropyLoss()\n\n        # Se entrena el modelo\n        trained_model, best_f1 = train_and_evaluate_audio(model,\n                                                 train_dataloader,\n                                                 dev_dataloader,\n                                                 num_epochs = epochs,\n                                                 lr = lr,\n                                                 patience = patience,\n                                                 multilabel = multilabel,\n                                                 verbose = verbose)\n\n        # Se predice en el conjunto de validación\n        y_pred_dev, y_probs_dev = predict_audio(trained_model, dev_dataloader, device)\n        \n        # Se obtiene las etiquetas reales\n        true_labels_dev = []\n        for _, _, labels in dev_dataloader:\n            true_labels_dev.append(labels)\n        true_labels_dev = torch.cat(true_labels_dev).cpu().numpy()\n        \n        # Se guardan los resultados de la evaluación\n        results[model_name] = {\n            'f1_score': best_f1,\n            'model': trained_model\n        }\n\n        print(f\"{model_name} - F1-Score: {best_f1:.4f}\\n\")\n\n    # Se selecciona el mejor modelo\n    best_model_name = max(results, key = lambda x: results[x]['f1_score'])\n    best_model = results[best_model_name]['model']\n\n    print(f\"\\nMejor modelo: {best_model_name} con F1-score: {results[best_model_name]['f1_score']:.4f}\")\n\n    return best_model_name, best_model, results[best_model_name]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def grid_search_audio_hyperparameters(model_name, train_dataset, dev_dataset, extra_features, multilabel = False, verbose = False):\n    \"\"\"\n    Función que realiza un 'grid search' sobre combinaciones de hiperparámetros para entrenar un modelo de audio basado en espectrogramas de Mel.\n\n    Args:\n        model_name (str): Nombre del backbone CNN a utilizar (están soportados 'vgg16' o 'efficientnet_b0').\n        train_dataset (Dataset): Dataset de entrenamiento 'EmotionDataset'.\n        dev_dataset (Dataset): Dataset de validación 'EmotionDataset'.\n        extra_features (int): Número de características adicionales a incluir en el modelo.\n        multilabel (bool, optional): Si es True, se trata de una tarea multietiqueta (MOSEI); si es False, es clasificación simple (MELD). Por defecto es False.\n        verbose (bool, optional): Si es True, se imprimen detalles del entrenamiento y evaluación. Por defecto es False.\n\n    Returns:\n        dict: Diccionario con la mejor combinación de hiperparámetros encontrados, incluyendo:\n            - 'batch_size': Tamaño del batch.\n            - 'epochs': Número de epochs.\n            - 'learning_rate': Tasa de aprendizaje.\n            - 'best_f1': Mejor F1-score alcanzado en validación.\n\n    Notes:\n        - Se prueban múltiples combinaciones de 'batch_size', 'epochs' y 'learning_rate'.\n        - Cada combinación se entrena usando 'train_and_evaluate_audio' y se evalúa con 'evaluate_audio'.\n        - Se utiliza 'CrossEntropyLoss' (MELD) o 'BCEWithLogitsLoss' (MOSEI) según el tipo de tarea.\n        - El criterio para seleccionar la mejor combinación es el mayor F1-score obtenido sobre el conjunto de validación.\n    \"\"\"\n    # Se define el grid de hiperparámetros a probar\n    batch_sizes = [32, 64]\n    learning_rates = [1e-4, 5e-5]\n    epochs_list = [8, 10]\n\n    # Se define la lista para los resultados y el device\n    results = []\n    device = 'cuda'\n\n    # Por cada combianción\n    for batch_size, epochs, lr in product(batch_sizes, epochs_list, learning_rates):\n        print(f\"\\n Combinación a probar: batch = {batch_size}, epochs = {epochs}, LR = {lr}\")\n        \n        # Se define la función de loss en función del dataset\n        #    - multilabel = True  --> MOSEI\n        #    - multilabel = False --> MELD\n        if multilabel:\n            loss_fn = nn.BCEWithLogitsLoss()\n        else:\n            loss_fn = nn.CrossEntropyLoss()\n\n        # Se crean  los dataloaders      \n        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2)\n        dev_dataloader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = False, num_workers = 2)\n\n         # Se define el modelo a estrenar\n        model = EmotionModel(backbone_name = model_name, \n                             num_extra_features = extra_features)\n        \n        # Se entrena el modelo con la combinación escogida\n        trained_model, _ = train_and_evaluate_audio(model,\n                                                 train_dataloader,\n                                                 dev_dataloader,\n                                                 num_epochs = epochs,\n                                                 lr = lr,\n                                                 patience = 2,\n                                                 multilabel = multilabel,\n                                                 verbose = verbose)\n\n        # Se evalua usando el modelo entrenado\n        dev_loss, dev_acc, dev_score = evaluate_audio(trained_model, \n                                                      dev_dataloader, \n                                                      loss_fn = loss_fn, \n                                                      device = device, \n                                                      multilabel = multilabel, \n                                                      verbose = verbose)\n        # Se guardan los resultados de la evaluación\n        results.append({\n            \"batch_size\": batch_size,\n            \"epochs\": epochs,\n            \"learning_rate\": lr,\n            \"best_f1\": dev_score\n        })\n\n    # Se ordenan los resultados de mejor a peor segun su F1-score\n    results = sorted(results, key = lambda x: x['best_f1'], reverse = True)\n\n    # Se muestra la mejor combinación encontrada\n    print(\"\\nMejor combinaión:\")\n    print(f\"F1-score = {results[0]['best_f1']:.4f} | batch = {results[0]['batch_size']}, epochs = {results[0]['epochs']}, LR = {results[0]['learning_rate']}\")\n\n    # Se devuelven los mejores hiperparámetros\n    return results[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Funciones auxiliares para la Evaluación","metadata":{}},{"cell_type":"markdown","source":"### Evaluación en texto","metadata":{}},{"cell_type":"code","source":"def predict(model, dataloader, device):\n    \"\"\"\n    Función que genera predicciones a partir de un modelo Transformer entrenado usando un DataLoader con entradas tokenizadas y características adicionales.\n\n    Args:\n        model (torch.nn.Module): Modelo entrenado que realiza la inferencia.\n        dataloader (DataLoader): DataLoader que contiene los batches de evaluación (input_ids, attention_mask, features).\n        device (str): Dispositivo (es 'cuda') sobre el cual se ejecutará la predicción.\n\n    Returns:\n        tuple:\n            numpy.ndarray: Vector de predicciones (índices de clase).\n            numpy.ndarray: Matriz de probabilidades para cada clase, con forma (n_samples, n_classes).\n\n    Notes:\n        - El modelo se pone en modo evaluación (`model.eval()`) y se desactiva el cálculo de gradientes con `torch.no_grad()`.\n        - Se aplica `softmax` sobre los logits del modelo para obtener las probabilidades por clase.\n        - Se usa `argmax` para extraer la clase con mayor probabilidad como predicción final.\n        - Los resultados se acumulan por batch y se devuelven como arrays de NumPy.\n    \"\"\"\n    # Se pone el modelo a modo evaluación\n    model.eval()\n\n    # Se manda el modleo al device\n    model.to(device)\n\n    # Se definen las listas de resultados\n    all_preds = []\n    all_probs = []\n\n    # Se le establece al modelo que no calcule o guarde los gradientes, así ahorrando memoria \n    # y aumentando la velocidad de las predicciones\n    with torch.no_grad():\n        # Por cada batch\n        for batch in dataloader:\n            # Se extrae la información necesaria del dataloader para enviarla al device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            features = batch['features'].to(device)\n\n            # Forward pass sin backpropagation\n            outputs = model(input_ids = input_ids, \n                            attention_mask = attention_mask, \n                            features = features)\n\n            # Se extraen las probabilidades y las predicciones\n            probabilities = torch.softmax(outputs, dim = 1)\n            predictions = torch.argmax(probabilities, dim = 1)\n\n            # Se almacenan los resultados\n            all_preds.extend(predictions.cpu().numpy())\n            all_probs.extend(probabilities.cpu().numpy())\n\n    # Se devuelven las predicciones y probabilidades\n    return np.array(all_preds), np.array(all_probs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_predictions(y_true, y_pred, y_probs, labels_names = None):\n    \"\"\"\n    Función que evalúa el rendimiento de un modelo Transformer de clasificación mediante métricas, matriz de confusión y curvas ROC.\n\n    Args:\n        y_true (array-like): Etiquetas verdaderas.\n        y_pred (array-like): Etiquetas predichas por el modelo.\n        y_probs (numpy.ndarray): Matriz de probabilidades por clase, de forma (n_samples, n_classes).\n        labels_names (list of str, optional): Nombres de las clases, usados para etiquetar los ejes y leyendas. Si no se proporciona, se usan las clases numéricas.\n\n    Returns:\n        None: La función imprime métricas por consola y muestra visualizaciones (matriz de confusión y curvas ROC).\n\n    Notes:\n        - Se calculan las siguientes métricas: Accuracy, Precisión, Recall, F1-score (promedio ponderado) y Classification Report completo.\n        - Las etiquetas verdaderas se binarizan con `label_binarize` para calcular las curvas ROC multicategoría de MOSEI.\n    \"\"\"\n    # Se calculan todas las métricas necesarias\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n    rec = recall_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n    f1 = f1_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n    report = classification_report(y_true, y_pred, zero_division = 0)\n\n    # Se muestran las métricas calculadas\n    print(\"\\nResultados de la evaluación:\")\n    print(f\"Accuracy:  {acc:.4f}\")\n    print(f\"Precision: {prec:.4f}\")\n    print(f\"Recall:    {rec:.4f}\")\n    print(f\"F1 Score:  {f1:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(report)\n\n    # Se calcula la matriz de confusión\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Se muestra la matriz de confusión\n    plt.figure(figsize = (6,5))\n    sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', \n                xticklabels = labels_names if labels_names else np.unique(y_true),\n                yticklabels = labels_names if labels_names else np.unique(y_true))\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Se extrae el número de clases predichas para calcular su AUC-ROC\n    n_classes = len(labels_names)\n\n    # Se binarizan las etiquetas verdaderas\n    y_true_bin = label_binarize(y_true, classes = list(range(n_classes)))\n\n    # Por cada clase, se calcula su curva ROC y se plotea\n    plt.figure(figsize = (8,6))\n    for i in range(n_classes):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label = f'{labels_names[i]} (AUC = {roc_auc:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curves')\n    plt.legend(loc = \"lower right\")\n    plt.grid()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluación en audio","metadata":{}},{"cell_type":"code","source":"def predict_audio(model, dataloader, device, multilabel = False):\n    \"\"\"\n    Función que genera predicciones a partir de un modelo de audio entrenado usando espectrogramas de Mel y características adicionales.\n\n    Args:\n        model (torch.nn.Module): Modelo entrenado que realiza la inferencia.\n        dataloader (DataLoader): DataLoader que contiene los batches de evaluación (mel, extra_features, labels).\n        device (str): Dispositivo (es 'cuda') sobre el cual se ejecutará la predicción.\n        multilabel (bool, optional): Si es True, se asume una tarea multietiqueta (MOSEI); si es False, clasificación única (MELD). Por defecto es False.\n\n    Returns:\n        tuple:\n            numpy.ndarray: Predicciones del modelo:\n                - Array binario para multietiqueta (forma: [n_samples, n_classes]).\n                - Array de clases predichas para clasificación simple (forma: [n_samples]).\n            numpy.ndarray: Probabilidades para cada clase, con forma (n_samples, n_classes).\n\n    Notes:\n        - El modelo se pone en modo evaluación (`model.eval()`).\n        - Se desactiva el cálculo de gradientes con `torch.no_grad()` para acelerar la inferencia.\n        - Se aplica `sigmoid` + umbral 0.5 para predicciones multietiqueta (MOSEI) y  `softmax` + `argmax`, para predicciones monoetiqueta (MELD).\n    \"\"\"\n    # Se pone el modelo a modo evaluación\n    model.eval()\n\n    # Se manda el modleo al device\n    model.to(device)\n\n    # Se definen las listas de resultados\n    all_preds = []\n    all_probs = []\n\n    # Se le establece al modelo que no calcule o guarde los gradientes, así ahorrando memoria \n    # y aumentando la velocidad de las predicciones\n    with torch.no_grad():\n        # Por cada Espectrograma de Mel\n        for mel, extra_features, _ in dataloader:\n            # Se extrae la información necesaria del dataloader para enviarla al device\n            mel = mel.to(device)\n            extra_features = extra_features.to(device)\n\n            # Forward pass sin backpropagation\n            outputs = model(mel, extra_features)\n\n            # Se extraen las probabilidades y las predicciones con\n            if multilabel:\n                # Sigmoid si es MOSEI\n                probabilities = torch.sigmoid(outputs)\n                predictions = (probabilities > 0.5).int()\n            else:\n                # Softmax si es MOSEI\n                probabilities = torch.softmax(outputs, dim = 1)\n                predictions = torch.argmax(probabilities, dim = 1)\n\n            # Se almacenan los resultados\n            all_preds.append(predictions.cpu().numpy())\n            all_probs.append(probabilities.cpu().numpy())\n\n    # Se devuelven las predicciones y probabilidades\n    return np.concatenate(all_preds), np.concatenate(all_probs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_audio_predictions(y_true, y_pred, y_probs, labels_names, multilabel = False):\n    \"\"\"\n    Función que evalúa las predicciones de un modelo de audio, mostrando métricas, matriz de confusión y curvas ROC para tareas monoetiqueta (MELD) o multietiquet (MOSEI).\n\n    Args:\n        y_true (array-like or pandas.DataFrame): Etiquetas reales. En tareas multietiqueta (MOSEI), debe tener forma (n_samples, n_classes).\n        y_pred (array-like): Etiquetas predichas por el modelo. En multietiqueta (MOSEI), es una matriz binaria (n_samples, n_classes).\n        y_probs (array-like): Probabilidades predichas por el modelo, con forma (n_samples, n_classes).\n        labels_names (list of str): Lista con los nombres de las clases, usada para visualizar etiquetas en gráficas y métricas.\n        multilabel (bool, optional): Si es True, se evalúa por clase de forma individual (MOSEI); si es False, se evalúa clasificación única (MELD). Por defecto es False.\n\n    Returns:\n        None: La función imprime métricas por consola y muestra visualizaciones (matriz de confusión y curvas ROC).\n\n    Notes:\n        - En tareas multietiqueta (MOSEI):\n            - Se evalúa Accuracy, Precisión, Recall y F1 por clase.\n            - Se plotean las curvas ROC para cada clase de forma individual.\n        - En tareas monoetiqueta (MELD):\n            - Se calcula el Accuracy global, Precisión, Recall, F1 ponderado y el classification report.\n            - Se visualiza la matriz de confusión con etiquetas de clase.\n            - Se plotean las curvas ROC por clase tras binarizar las etiquetas reales.\n    \"\"\"\n    if multilabel:\n        # En el caso de MOSEI, al ser multilabel, se evalúan por separado cada clase\n        print(\"\\nResultados multilabel (por clase):\")\n        y_true = y_true.values\n        y_pred = y_pred if isinstance(y_pred, np.ndarray) else np.array(y_pred)\n        y_probs = y_probs if isinstance(y_probs, np.ndarray) else np.array(y_probs)\n        for idx, label in enumerate(labels_names):\n            # Se extraen las predicciones concretas de esta clase\n            y_true_class = y_true[:, idx]\n            y_pred_class = y_pred[:, idx]\n\n            # Se binariza y_true_class\n            y_true_class = (y_true_class >= 0.5).astype(int)\n\n            # Se calculan todas las métricas necesarias\n            acc = accuracy_score(y_true_class, y_pred_class)\n            prec = precision_score(y_true_class, y_pred_class, zero_division = 0)\n            rec = recall_score(y_true_class, y_pred_class, zero_division = 0)\n            f1 = f1_score(y_true_class, y_pred_class, zero_division = 0)\n            print(f\"{label}: ACC = {acc:.4f}, Precision = {prec:.4f}, Recall = {rec:.4f}, F1 = {f1:.4f}\")\n        \n        # Se calcula el AUC de cada clase\n        plt.figure(figsize = (8,6))\n        print(\"\\nAUC para cada clase:\")\n        for i in range(y_probs.shape[1]):\n            try:\n                fpr, tpr, _ = roc_curve(y_true[:, i], y_probs[:, i])\n                roc_auc = auc(fpr, tpr)\n                print(f\"{labels_names[i]} AUC = {roc_auc:.2f}\")\n                plt.plot(fpr, tpr, label = f'{labels_names[i]} (AUC = {roc_auc:.2f})')\n            except:\n                print(f\"{labels_names[i]} AUC no disponible\")\n\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curves Multilabel')\n        plt.legend(loc = \"lower right\")\n        plt.grid()\n        plt.show()\n\n    else:\n        # En el caso de MELD, al solo tener un único valor a predeci, se evalúa todo junto\n        # Se calculan todas las métricas necesarias\n        acc = accuracy_score(y_true, y_pred)\n        prec = precision_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n        rec = recall_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n        f1 = f1_score(y_true, y_pred, average = 'weighted', zero_division = 0)\n        report = classification_report(y_true, y_pred, target_names = labels_names, zero_division = 0)\n\n        print(\"\\nResultados de la evaluación:\")\n        print(f\"Accuracy:  {acc:.4f}\")\n        print(f\"Precision: {prec:.4f}\")\n        print(f\"Recall:    {rec:.4f}\")\n        print(f\"F1 Score:  {f1:.4f}\")\n        print(\"\\nClassification Report:\")\n        print(report)\n\n        # Se calcula la matriz de confusión\n        cm = confusion_matrix(y_true, y_pred)\n\n        # Se muestra la matriz de confusión\n        plt.figure(figsize = (8,6))\n        sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', \n                    xticklabels = labels_names if labels_names else np.unique(y_true),\n                    yticklabels = labels_names if labels_names else np.unique(y_true))\n        plt.xlabel('Predicted Labels')\n        plt.ylabel('True Labels')\n        plt.title('Confusion Matrix')\n        plt.show()\n\n        # Se extrae el número de clases predichas para calcular su AUC-ROC\n        n_classes = len(labels_names)\n\n        # Se binarizan las etiquetas verdaderas\n        y_true_bin = label_binarize(y_true, classes = list(range(n_classes)))\n\n        # Por cada clase, se calcula su curva ROC y se plotea\n        plt.figure(figsize = (8,6))\n        for i in range(n_classes):\n            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n            roc_auc = auc(fpr, tpr)\n            plt.plot(fpr, tpr, label = f'{labels_names[i]} (AUC = {roc_auc:.2f})')\n\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curves')\n        plt.legend(loc = \"lower right\")\n        plt.grid()\n        plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}